{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKL0qxwcHjVj"
      },
      "outputs": [],
      "source": [
        "!which python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e46bab3a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZsCwsx9HjVk"
      },
      "outputs": [],
      "source": [
        "!which python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6a22dfe"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "currency_symbol_dict = {\n",
        "    # --- SAFE: DISTINCT SYMBOLS ---\n",
        "    'EUR': '€',       # Euro\n",
        "    'GBP': '£',       # British Pound Sterling\n",
        "    'INR': '₹',       # Indian Rupee\n",
        "    'JPY': 'JP¥',     # Japanese Yen\n",
        "    'CNY': 'CN¥',     # Chinese Yuan\n",
        "    'RUB': '₽',       # Russian Ruble\n",
        "    'NGN': '₦',       # Nigerian Naira\n",
        "    'THB': '฿',       # Thai Baht\n",
        "    'VND': '₫',       # Vietnamese Dong\n",
        "    'KRW': '₩',       # South Korean Won\n",
        "    'KPW': '₩',       # North Korean Won\n",
        "    'TRY': '₺',       # Turkish Lira\n",
        "    'GHS': '₵',       # Ghanaian Cedi\n",
        "    'PHP': '₱',       # Philippine Peso\n",
        "    'ILS': '₪',       # Israeli New Shekel\n",
        "    'CRC': '₡',       # Costa Rican Colón\n",
        "    'PLN': 'zł',      # Polish Zloty\n",
        "    'CZK': 'Kč',      # Czech Koruna\n",
        "    'MNT': '₮',       # Mongolian Tögrög\n",
        "    'UAH': '₴',       # Ukrainian Hryvnia\n",
        "    'GEL': '₾',       # Georgian Lari\n",
        "    'AMD': '֏',       # Armenian Dram\n",
        "    'AZN': '₼',       # Azerbaijani Manat\n",
        "    'KZT': '₸',       # Kazakhstani Tenge\n",
        "    'LAK': '₭',       # Lao Kip\n",
        "    'KHR': '៛',       # Cambodian Riel\n",
        "    'BGN': 'лв',      # Bulgarian Lev\n",
        "    'MKD': 'ден',     # Macedonian Denar\n",
        "    'RSD': 'дин',     # Serbian Dinar\n",
        "\n",
        "    # --- ARABIC / DISTINCT SCRIPTS ---\n",
        "    'AED': 'د.إ',     # UAE Dirham\n",
        "    'SAR': 'ر.س',     # Saudi Riyal\n",
        "    'DZD': 'د.ج',     # Algerian Dinar\n",
        "    'LYD': 'ل.د',     # Libyan Dinar\n",
        "    'MAD': 'د.م.',    # Moroccan Dirham\n",
        "    'IQD': 'ع.د',     # Iraqi Dinar\n",
        "    'IRR': '﷼',       # Iranian Rial\n",
        "    'YER': '﷼',       # Yemeni Rial\n",
        "    'OMR': 'ر.ع.',    # Omani Rial\n",
        "    'QAR': 'ر.ق',     # Qatari Riyal\n",
        "    'JOD': 'د.ا',     # Jordanian Dinar\n",
        "    'KWD': 'د.ك',     # Kuwaiti Dinar\n",
        "    'TND': 'د.ت',     # Tunisian Dinar\n",
        "    'SDG': 'ج.س.',    # Sudanese Pound\n",
        "    'LBP': 'ل.ل',     # Lebanese Pound\n",
        "    'AFN': '؋',       # Afghan Afghani\n",
        "    'BHD': '.د.ب',    # Bahraini Dinar\n",
        "    'NPR': 'रू',      # Nepalese Rupee\n",
        "    'BDT': '৳',       # Bangladeshi Taka\n",
        "\n",
        "    # --- DOLLAR VARIANTS (KEPT AS REQUESTED) ---\n",
        "    'USD': 'US$',       # US Dollar\n",
        "    # 'ARS': '$',       # Argentine Peso\n",
        "    # 'CLP': '$',       # Chilean Peso\n",
        "    # 'COP': '$',       # Colombian Peso\n",
        "    'MXN': 'MEX$',     # Mexican Peso\n",
        "    'AUD': 'A$',      # Australian Dollar\n",
        "    'CAD': 'C$',      # Canadian Dollar\n",
        "    'SGD': 'S$',      # Singapore Dollar\n",
        "    'BRL': 'R$',      # Brazilian Real\n",
        "    'HKD': 'HK$',     # Hong Kong Dollar\n",
        "    'NZD': 'NZ$',     # New Zealand Dollar\n",
        "    'BSD': 'B$',      # Bahamian Dollar\n",
        "    'BZD': 'BZ$',     # Belize Dollar\n",
        "    'JMD': 'J$',      # Jamaican Dollar\n",
        "    'TTD': 'TT$',     # Trinidad and Tobago Dollar\n",
        "    'XCD': 'EC$',     # East Caribbean Dollar\n",
        "    'FJD': 'FJ$',     # Fijian Dollar\n",
        "    'SBD': 'SI$',     # Solomon Islands Dollar\n",
        "    'KYD': 'CI$',     # Cayman Islands Dollar\n",
        "    'LRD': 'L$',      # Liberian Dollar\n",
        "    'NAD': 'N$',      # Namibian Dollar\n",
        "    'UYU': '$U',      # Uruguayan Peso,\n",
        "     'SRD': 'Sr$',     # Surinamese Dollar (Suggesting 'Sr$' for distinctness),\n",
        "    'EGP':'E£',\n",
        "    'BND': 'B$',\n",
        "    'DOP':'RD$',\n",
        "    'GYD':'G$',\n",
        "    'KGS':'⃀',\n",
        "    'MOP': 'MOP$',    # Macanese Pataca\n",
        "    'PAB':'B/.',\n",
        "    'PEN': 'S/.',      # Peruvian Sol\n",
        "    'PYG': '₲',       # Paraguayan Guaraní,\n",
        "    'SOS':'Sh.So.',\n",
        "    'SYP': '£S',      # Syrian Pound\n",
        "    'TOP': 'T$',      # Tongan Paʻanga\n",
        "     'TWD': 'NT$',     # New Taiwan Dollar\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "currency_name_dict = {\n",
        "    'USD': 'United States Dollar',\n",
        "    'INR': 'Indian Rupee',\n",
        "    'EUR': 'Euro',\n",
        "    'GBP': 'British Pound Sterling',\n",
        "    'JPY': 'Japanese Yen',\n",
        "    'CHF': 'Swiss Franc',\n",
        "    'KPW': 'North Korean Won',\n",
        "    'PKR': 'Pakistani Rupee',\n",
        "    'CNY': 'Chinese Yuan',\n",
        "    'AUD': 'Australian Dollar',\n",
        "    'CAD': 'Canadian Dollar',\n",
        "    'MXN': 'Mexican Peso',\n",
        "    'RUB': 'Russian Ruble',\n",
        "    'ZAR': 'South African Rand',\n",
        "    'NGN': 'Nigerian Naira',\n",
        "    'THB': 'Thai Baht',\n",
        "    'VND': 'Vietamese Dong',\n",
        "    'IDR': 'Indonesian Rupiah',\n",
        "    'KRW': 'South Korean Won',\n",
        "    'PLN': 'Polish Złoty',\n",
        "    'SEK': 'Swedish Krona',\n",
        "    'TRY': 'Turkish Lira',\n",
        "    'BRL': 'Brazilian Real',\n",
        "    'AED': 'United Arab Emirates Dirham',\n",
        "    'SAR': 'Saudi Riyal',\n",
        "    'SCR': 'Seychellois Rupee',\n",
        "    'YER': 'Yemeni Rial',\n",
        "    'SLL': 'Sierra Leonean Leone',\n",
        "    'MWK': 'Malawian Kwacha',\n",
        "    'GHS': 'Ghanaian Cedi',\n",
        "    'UGX': 'Ugandan Shilling',\n",
        "    'TZS': 'Tanzanian Shilling',\n",
        "    'XOF': 'West African CFA Franc',\n",
        "    'DZD': 'Algerian Dinar',\n",
        "    'EGP': 'Egyptian Pound',\n",
        "    'PHP': 'Philippine Peso',\n",
        "    'MYR': 'Malaysian Ringgit',\n",
        "    'LKR': 'Sri Lankan Rupee',\n",
        "    'NPR': 'Nepalese Rupee',\n",
        "    'BDT': 'Bangladeshi Taka',\n",
        "    'OMR': 'Omani Rial',\n",
        "    'SGD': 'Singapore Dollar',\n",
        "\n",
        "    'AFN': 'Afghan Afghani',\n",
        "    'ALL': 'Albanian Lek',\n",
        "    'AMD': 'Armenian Dram',\n",
        "    'AOA': 'Angolan Kwanza',\n",
        "    'ARS': 'Argentine Peso',\n",
        "    'AZN': 'Azerbaijani Manat',\n",
        "    'BAM': 'Bosnia and Herzegovina Convertible Mark',\n",
        "    'BBD': 'Barbadian Dollar',\n",
        "    'BGN': 'Bulgarian Lev',\n",
        "    'BHD': 'Bahraini Dinar',\n",
        "    'BIF': 'Burundian Franc',\n",
        "    'BMD': 'Bermudian Dollar',\n",
        "    'BND': 'Brunei Dollar',\n",
        "    'BOB': 'Bolivian Boliviano',\n",
        "    'BSD': 'Bahamian Dollar',\n",
        "    'BTN': 'Bhutanese Ngultrum',\n",
        "    'BWP': 'Botswana Pula',\n",
        "    'BYN': 'Belarusian Ruble',\n",
        "    'BZD': 'Belize Dollar',\n",
        "    'CDF': 'Congolese Franc',\n",
        "    'CLP': 'Chilean Peso',\n",
        "    'COP': 'Colombian Peso',\n",
        "    'CRC': 'Costa Rican Colón',\n",
        "    'CUP': 'Cuban Peso',\n",
        "    'CVE': 'Cape Verdean Escudo',\n",
        "    'CZK': 'Czech Koruna',\n",
        "    'DJF': 'Djiboutian Franc',\n",
        "    'DKK': 'Danish Krone',\n",
        "    'DOP': 'Dominican Peso',\n",
        "    'ERN': 'Eritrean Nakfa',\n",
        "    'ETB': 'Ethiopian Birr',\n",
        "    'FJD': 'Fijian Dollar',\n",
        "    'GEL': 'Georgian Lari',\n",
        "    'GMD': 'Gambian Dalasi',\n",
        "    'GNF': 'Guinean Franc',\n",
        "    'GTQ': 'Guatemalan Quetzal',\n",
        "    'GYD': 'Guyanese Dollar',\n",
        "    'HKD': 'Hong Kong Dollar',\n",
        "    'HNL': 'Honduran Lempira',\n",
        "    'HTG': 'Haitian Gourde',\n",
        "    'HUF': 'Hungarian Forint',\n",
        "    'ILS': 'Israeli New Shekel',\n",
        "    'IQD': 'Iraqi Dinar',\n",
        "    'IRR': 'Iranian Rial',\n",
        "    'ISK': 'Icelandic Króna',\n",
        "    'JMD': 'Jamaican Dollar',\n",
        "    'JOD': 'Jordanian Dinar',\n",
        "    'KES': 'Kenyan Shilling',\n",
        "    'KGS': 'Kyrgyzstani Som',\n",
        "    'KHR': 'Cambodian Riel',\n",
        "    'KMF': 'Comorian Franc',\n",
        "    'KWD': 'Kuwaiti Dinar',\n",
        "    'KYD': 'Cayman Islands Dollar',\n",
        "    'KZT': 'Kazakhstani Tenge',\n",
        "    'LAK': 'Lao Kip',\n",
        "    'LBP': 'Lebanese Pound',\n",
        "    'LRD': 'Liberian Dollar',\n",
        "    'LSL': 'Lesotho Loti',\n",
        "    'LYD': 'Libyan Dinar',\n",
        "    'MAD': 'Moroccan Dirham',\n",
        "    'MDL': 'Moldovan Leu',\n",
        "    'MGA': 'Malagasy Ariary',\n",
        "    'MKD': 'Macedonian Denar',\n",
        "    'MMK': 'Myanmar Kyat',\n",
        "    'MNT': 'Mongolian Tögrög',\n",
        "    'MOP': 'Macanese Pataca',\n",
        "    'MRU': 'Mauritanian Ouguiya',\n",
        "    'MUR': 'Mauritian Rupee',\n",
        "    'MVR': 'Maldivian Rufiyaa',\n",
        "    'MZN': 'Mozambican Metical',\n",
        "    'NAD': 'Namibian Dollar',\n",
        "    'NIO': 'Nicaraguan Córdoba',\n",
        "    'NOK': 'Norwegian Krone',\n",
        "    'NZD': 'New Zealand Dollar',\n",
        "    'PAB': 'Panamanian Balboa',\n",
        "    'PEN': 'Peruvian Sol',\n",
        "    'PGK': 'Papua New Guinean Kina',\n",
        "    'PYG': 'Paraguayan Guaraní',\n",
        "    'QAR': 'Qatari Riyal',\n",
        "    'RON': 'Romanian Leu',\n",
        "    'RSD': 'Serbian Dinar',\n",
        "    'RWF': 'Rwandan Franc',\n",
        "    'SBD': 'Solomon Islands Dollar',\n",
        "    'SDG': 'Sudanese Pound',\n",
        "    'SHP': 'Saint Helena Pound',\n",
        "    'SOS': 'Somali Shilling',\n",
        "    'SRD': 'Surinamese Dollar',\n",
        "    'SSP': 'South Sudanese Pound',\n",
        "    'STN': 'São Tomé and Príncipe Dobra',\n",
        "    'SVC': 'Salvadoran Colón',\n",
        "    'SYP': 'Syrian Pound',\n",
        "    'SZL': 'Eswatini Lilangeni',\n",
        "    'TJS': 'Tajikistani Somoni',\n",
        "    'TMT': 'Turkmenistani Manat',\n",
        "    'TND': 'Tunisian Dinar',\n",
        "    'TOP': 'Tongan Paʻanga',\n",
        "    'TTD': 'Trinidad and Tobago Dollar',\n",
        "    'TWD': 'New Taiwan Dollar',\n",
        "    'UAH': 'Ukrainian Hryvnia',\n",
        "    'UYU': 'Uruguayan Peso',\n",
        "    'UZS': 'Uzbekistani Som',\n",
        "    'VES': 'Venezuelan Bolívar',\n",
        "    'VUV': 'Vanuatu Vatu',\n",
        "    'WST': 'Samoan Tālā',\n",
        "    'XAF': 'Central African CFA Franc',\n",
        "    'XCD': 'East Caribbean Dollar',\n",
        "    'XPF': 'CFP Franc',\n",
        "    'ZMW': 'Zambian Kwacha',\n",
        "    'ZWG': 'Zimbabwean Gold'\n",
        "}\n",
        "    # 'USD': '$',       # US Dollar\n",
        "    # 'INR': '₹',       # Indian Rupee\n",
        "    # 'EUR': '€',       # Euro\n",
        "    # 'GBP': '£',       # British Pound Sterling\n",
        "\n",
        "currency_identifiers = ['EURO', 'EUR', 'USD', '$','€','£']\n",
        "currency_pattern = '|'.join([re.escape(str(identifier)) for identifier in currency_identifiers])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yTTjQiNovVk"
      },
      "outputs": [],
      "source": [
        "currency_name_dict = {k: \" \" + v + \" \" for k, v in currency_name_dict.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWNjuMMKHjVn"
      },
      "outputs": [],
      "source": [
        "currency_name_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_YD4i5PHjVo"
      },
      "outputs": [],
      "source": [
        "len(currency_symbol_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veXPweMUHjVo"
      },
      "outputs": [],
      "source": [
        "len(currency_name_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7A14Gfx-8ae"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"HF_TOKEN\"] = \"your_token\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0db5045e"
      },
      "outputs": [],
      "source": [
        "# Load and filter FinanceMTEB/financial_phrasebank dataset\n",
        "dataset_name = \"FinanceMTEB/financial_phrasebank\"\n",
        "print(f\"Loading dataset: {dataset_name}\")\n",
        "ds_fin = load_dataset(dataset_name)\n",
        "\n",
        "filtered_ds_fin = {}\n",
        "for split_name, dataset_split in ds_fin.items():\n",
        "    if split_name == 'train':\n",
        "        print(f\"Applying currency pattern filter for split: {split_name}\")\n",
        "        filtered_split = dataset_split.filter(lambda example: bool(re.search(currency_pattern, example['text'])))\n",
        "        filtered_ds_fin[split_name] = filtered_split\n",
        "    else:\n",
        "        print(f\"Applying currency pattern filter for split: {split_name}\")\n",
        "        filtered_split = dataset_split.filter(lambda example: bool(re.search(currency_pattern, example['text'])))\n",
        "        filtered_ds_fin[split_name] = filtered_split\n",
        "\n",
        "train_texts = filtered_ds_fin['train']['text']\n",
        "train_labels = filtered_ds_fin['train']['label']\n",
        "test_texts = filtered_ds_fin['test']['text']\n",
        "test_labels = filtered_ds_fin['test']['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92acb4e9"
      },
      "outputs": [],
      "source": [
        "REPLACEMENT_TYPE='SYMBOL'\n",
        "# REPLACEMENT_TYPE='ACRONYM'\n",
        "# REPLACEMENT_TYPE='NAME'\n",
        "\n",
        "\n",
        "unique_symbols = list(currency_symbol_dict.values())\n",
        "unique_iso_codes = list(list(currency_symbol_dict.keys()))\n",
        "target_replacement_strings = list(set(unique_symbols).union(set(unique_iso_codes)))[0:4]\n",
        "\n",
        "target_replacement_strings = list(set(unique_symbols).union(set(unique_iso_codes)))[0:4]\n",
        "\n",
        "\n",
        "\n",
        "if REPLACEMENT_TYPE=='SYMBOL':\n",
        "    target_replacement_strings = list(set(unique_symbols))\n",
        "\n",
        "if REPLACEMENT_TYPE=='NAME':\n",
        "    target_replacement_strings = list(currency_name_dict.values())\n",
        "    target_replacement_strings = [\" \" + v + \" \" for v in target_replacement_strings]\n",
        "\n",
        "\n",
        "if REPLACEMENT_TYPE=='ACRONYM':\n",
        "    target_replacement_strings = list(set(unique_iso_codes))\n",
        "\n",
        "\n",
        "print(f\"Total number of unique currency replacement strings: {len(target_replacement_strings)}\")\n",
        "print(f\"First 10 unique currency replacement strings: {target_replacement_strings[:10]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9mPH6EU_7Wx"
      },
      "outputs": [],
      "source": [
        "currency_pattern"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9NMJyVCiTdG"
      },
      "outputs": [],
      "source": [
        "print(f\"Current currency_pattern: '{currency_pattern}'\")\n",
        "# The pattern 'EURO' is listed before '\\\\ EUR', ensuring it is prioritized if both could match at a given position."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2b92766"
      },
      "outputs": [],
      "source": [
        "# Compile regex outside the loop for efficiency\n",
        "compiled_currency_pattern = re.compile(currency_pattern, flags=re.IGNORECASE)\n",
        "compiled_currency_pattern\n",
        "len(test_texts)\n",
        "\n",
        "original_texts_for_df = []\n",
        "modified_texts_for_df = []\n",
        "processing_status_for_df = []\n",
        "true_labels_for_df = []\n",
        "\n",
        "for i, text in enumerate(test_texts):\n",
        "    found_currencies = re.findall(compiled_currency_pattern, text)\n",
        "\n",
        "    if found_currencies:\n",
        "        unique_found_currencies = set(found_currencies)\n",
        "\n",
        "        if len(unique_found_currencies) == 1:\n",
        "            modified_text = compiled_currency_pattern.sub(\"****[REPLACE]****\", text)\n",
        "            processing_status = 'Processed (Single Currency)'\n",
        "        else:\n",
        "            modified_text = text\n",
        "            processing_status = 'Skipped (Multiple Currencies)'\n",
        "    else:\n",
        "        modified_text = text\n",
        "        processing_status = 'No Currency Found'\n",
        "\n",
        "    original_texts_for_df.append(text)\n",
        "    modified_texts_for_df.append(modified_text)\n",
        "    processing_status_for_df.append(processing_status)\n",
        "    true_labels_for_df.append(test_labels[i]) # Append the corresponding true label\n",
        "\n",
        "before_after_df = pd.DataFrame({\n",
        "    'original_text': original_texts_for_df,\n",
        "    'modified_text': modified_texts_for_df,\n",
        "    'processing_status': processing_status_for_df,\n",
        "    'true_label': true_labels_for_df # Add the true_label column\n",
        "})\n",
        "\n",
        "print(\"DataFrame with original, modified texts, processing status, and true labels created successfully.\")\n",
        "display(before_after_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_w-O_7sc0YH"
      },
      "outputs": [],
      "source": [
        "len(before_after_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rAodu4OHjVq"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.max_colwidth', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLOgGyJCh-U_"
      },
      "outputs": [],
      "source": [
        "len(before_after_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Op7fadwfr3D"
      },
      "outputs": [],
      "source": [
        "display(before_after_df.sort_values(by='processing_status'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZaqkAKZUhzjm"
      },
      "outputs": [],
      "source": [
        "currency_pattern"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyiCQU9Yc-At"
      },
      "outputs": [],
      "source": [
        "before_after_df = before_after_df[before_after_df['processing_status'] != 'Skipped (Multiple Currencies)']\n",
        "\n",
        "print(\"DataFrame filtered successfully to exclude 'Skipped (Multiple Currencies)' rows.\")\n",
        "display(before_after_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0lD6AhKCTJT"
      },
      "outputs": [],
      "source": [
        "test_texts = before_after_df['original_text'].tolist()\n",
        "test_labels = before_after_df['true_label'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8c558cd7"
      },
      "outputs": [],
      "source": [
        "len(before_after_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iOHv880DVL-"
      },
      "source": [
        "<!-- remove_subset_string = \"lemiste City is the environment\" -->\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkdUTueMHjVs"
      },
      "outputs": [],
      "source": [
        "remove_subset_string = \"lemiste City is the environment\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUpxUo8FHjVs"
      },
      "outputs": [],
      "source": [
        "len(before_after_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTDMLrvLHjVs"
      },
      "outputs": [],
      "source": [
        "\n",
        "before_after_df = before_after_df[\n",
        "    ~before_after_df['original_text'].str.contains(remove_subset_string, case=False, na=False, regex=False)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hzPgngMHjVs"
      },
      "outputs": [],
      "source": [
        "len(before_after_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPCOtNZIAunt"
      },
      "outputs": [],
      "source": [
        "display(before_after_df.sort_values(by='processing_status'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HC95wZXCgDB3"
      },
      "outputs": [],
      "source": [
        "before_after_df=before_after_df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSVCDTlVtP0R"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.max_colwidth', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlhIyq3-tPxi"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score\n",
        "import pandas as pd\n",
        "\n",
        "def calculate_metrics(group):\n",
        "    if len(group) == 0:\n",
        "        return pd.Series({'accuracy': 0.0, 'f1_score': 0.0, 'macro_precision': 0.0})\n",
        "\n",
        "    accuracy = accuracy_score(group['numerical_true_label'], group['numerical_modified_prediction'])\n",
        "    f1 = f1_score(group['numerical_true_label'], group['numerical_modified_prediction'], average='weighted', zero_division=0)\n",
        "    macro_precision = precision_score(group['numerical_true_label'], group['numerical_modified_prediction'], average='macro', zero_division=0)\n",
        "    return pd.Series({'accuracy': accuracy, 'f1_score': f1, 'macro_precision': macro_precision})\n",
        "\n",
        "print(\"Defined calculate_metrics function, now including macro_precision.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnqLjvXuHjVu"
      },
      "outputs": [],
      "source": [
        "\n",
        "# target_models = [\"ProsusAI/finbert\",\"FinLang/finance-embeddings-investopedia\"]#,\"intfloat/multilingual-e5-large\", \"intfloat/multilingual-e5-large-instruct\",\"Alibaba-NLP/gte-large-en-v1.5\",\"Alibaba-NLP/gte-multilingual-base\",\"jinaai/jina-embeddings-v3\",\\\n",
        "\n",
        "#                               # \"jinaai/jina-embeddings-v2-base-en\",\"BAAI/bge-m3\",\"Snowflake/snowflake-arctic-embed-m-v1.5\",\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\",\"sentence-transformers/all-mpnet-base-v2\",\\\n",
        "\n",
        "#                               # \"Qwen/Qwen3-Embedding-0.6B\",\"Qwen/Qwen3-Embedding-4B\",\"Alibaba-NLP/gte-Qwen2-1.5B-instruct\",\"google/embeddinggemma-300M\",]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "target_models = [ \"Qwen/Qwen3-Embedding-0.6B\",\"google/embeddinggemma-300M\",\"Qwen/Qwen3-Embedding-4B\", \"ProsusAI/finbert\",\"FinLang/finance-embeddings-investopedia\",\"intfloat/multilingual-e5-large\", \"intfloat/multilingual-e5-large-instruct\",\"Alibaba-NLP/gte-large-en-v1.5\",\"Alibaba-NLP/gte-multilingual-base\",\\\n",
        "\n",
        "                              \"jinaai/jina-embeddings-v2-base-en\",\"BAAI/bge-m3\",\"Snowflake/snowflake-arctic-embed-m-v1.5\",\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\",\"sentence-transformers/all-mpnet-base-v2\",\\\n",
        "\n",
        "                             ]\n",
        "#\"\",\"Alibaba-NLP/gte-Qwen2-1.5B-instruct\",,]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pigu0HtiHjVv"
      },
      "outputs": [],
      "source": [
        "sorted(target_models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8e0smJPsjTnf"
      },
      "outputs": [],
      "source": [
        "len(target_models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVxkCueMN4ce"
      },
      "outputs": [],
      "source": [
        "device='cuda'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSJytDdwLN8Q"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer\n",
        "from transformers.pipelines import Pipeline\n",
        "from transformers.pipelines import PIPELINE_REGISTRY\n",
        "\n",
        "\n",
        "class FinBERTPipeline(Pipeline):\n",
        "    def _sanitize_parameters(self, **kwargs):\n",
        "        preprocess_kwargs = {}\n",
        "        if \"max_length\" in kwargs:\n",
        "            preprocess_kwargs[\"max_length\"] = kwargs[\"max_length\"]\n",
        "        return {}, preprocess_kwargs, {}\n",
        "\n",
        "    def preprocess(self, inputs, **kwargs):\n",
        "        tokenizer = self.tokenizer\n",
        "        return tokenizer(inputs, return_tensors=self.framework, padding=True, truncation=True, **kwargs)\n",
        "\n",
        "    def _forward(self, model_inputs, **kwargs):\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(**model_inputs, output_hidden_states=True)\n",
        "            # Typically, the last hidden state of the [CLS] token is used as the sentence embedding\n",
        "            cls_token_embeddings = outputs.hidden_states[-1][:, 0, :].cpu().numpy()\n",
        "        return {\"embeddings\": cls_token_embeddings}\n",
        "\n",
        "    def postprocess(self, model_outputs, **kwargs):\n",
        "        return model_outputs[\"embeddings\"]\n",
        "\n",
        "PIPELINE_REGISTRY.register_pipeline(\n",
        "    \"finbert-embedding\",\n",
        "    pipeline_class=FinBERTPipeline,\n",
        "    pt_model=AutoModelForSequenceClassification,\n",
        "    default={\"model\": \"ProsusAI/finbert\", \"revision\": \"main\"}\n",
        ")\n",
        "\n",
        "print(\"FinBERTPipeline class defined and registered.\")\n",
        "\n",
        "\n",
        "def embed_using_finbert(pipe, list_text):\n",
        "\n",
        "    all_embeddings_list = pipe(list_text, padding=True, truncation=True, max_length=128)\n",
        "\n",
        "    return all_embeddings_list\n",
        "\n",
        "\n",
        "\n",
        "finbert_model = AutoModelForSequenceClassification.from_pretrained('ProsusAI/finbert').to(device)\n",
        "finbert_tokenizer = AutoTokenizer.from_pretrained('ProsusAI/finbert')\n",
        "finbert_pipe = pipeline(\n",
        "    \"finbert-embedding\",\n",
        "    model=finbert_model,\n",
        "    tokenizer=finbert_tokenizer,\n",
        "    device=0 if device == \"cuda\" else -1 # Use GPU 0 if CUDA, else CPU -1\n",
        ")\n",
        "currency_embeddings_map = embed_using_finbert(finbert_pipe, ['a','b'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def analyze_currency_impact_exhaustive(logistic_predictor, model_name, embedding_model, test_texts, test_labels, test_embeddings, currency_pattern, single_replacement_string):\n",
        "    impactful_changes = []\n",
        "    modified_texts_to_encode = []\n",
        "    original_prediction_list = []\n",
        "    original_proba_list = []\n",
        "    true_label_list = []\n",
        "    original_text_list = []\n",
        "\n",
        "\n",
        "    compiled_currency_pattern = re.compile(currency_pattern, flags=re.IGNORECASE)\n",
        "\n",
        "    for i, text in enumerate(test_texts):\n",
        "        # Get probabilities for the original text\n",
        "        original_probas = logistic_predictor.predict_proba(test_embeddings[i].reshape(1, -1))[0]\n",
        "        original_prediction = np.argmax(original_probas) # Derive class label from probabilities\n",
        "\n",
        "        true_label = test_labels[i]\n",
        "\n",
        "        if compiled_currency_pattern.search(text):\n",
        "            # Replace all occurrences of currency mentions with the single_replacement_string\n",
        "            modified_text = compiled_currency_pattern.sub(single_replacement_string, text)\n",
        "            modified_texts_to_encode.append(modified_text)\n",
        "            original_prediction_list.append(original_prediction)\n",
        "            original_proba_list.append(original_probas)\n",
        "            true_label_list.append(true_label)\n",
        "            original_text_list.append(text)\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "    if modified_texts_to_encode:\n",
        "        modified_embeddings = encode_text(modified_texts_to_encode[:], model_name, embedding_model).squeeze()\n",
        "        modified_probas = logistic_predictor.predict_proba(modified_embeddings)\n",
        "        modified_predictions = np.argmax(modified_probas, axis=1) # Derive class labels from probabilities\n",
        "\n",
        "        for j in range(len(modified_texts_to_encode)):\n",
        "            impactful_changes.append({\n",
        "                'original_text': original_text_list[j],\n",
        "                'replaced_with': single_replacement_string,\n",
        "                'modified_text': modified_texts_to_encode[j],\n",
        "                'original_prediction': original_prediction_list[j],\n",
        "                'original_probabilities': original_proba_list[j].tolist(),\n",
        "                'modified_prediction': modified_predictions[j],\n",
        "                'modified_probabilities': modified_probas[j].tolist(),\n",
        "                'true_label': true_label_list[j]\n",
        "            })\n",
        "\n",
        "    print('len(impactful_changes)', len(impactful_changes))\n",
        "    return impactful_changes\n",
        "\n",
        "print(\"Re-defined analyze_currency_impact_exhaustive function to include probabilities.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "johfvzyldbvq"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel\n",
        "# Initialize the model\n",
        "model = AutoModel.from_pretrained(\"jinaai/jina-embeddings-v4\", trust_remote_code=True)\n",
        "model.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mq5Qt51MeFYe"
      },
      "outputs": [],
      "source": [
        "model = SentenceTransformer(\"jinaai/jina-embeddings-v3\", trust_remote_code=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_WoWkyqd30R"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers>=4.52.0 torch>=2.6.0 peft>=0.15.2 torchvision pillow\n",
        "from transformers import AutoModel\n",
        "# Initialize the model\n",
        "model = AutoModel.from_pretrained(\"jinaai/jina-embeddings-v4\", trust_remote_code=True)\n",
        "model.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60D3boBlLPB_"
      },
      "outputs": [],
      "source": [
        "def encode_text(list_text, model_name, embedding_model):\n",
        "    if model_name == 'ProsusAI/finbert':\n",
        "        return np.array(embed_using_finbert(finbert_pipe, list_text))\n",
        "    else:\n",
        "        return embedding_model.encode(list_text, convert_to_numpy=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXH8tyFQE_cH"
      },
      "outputs": [],
      "source": [
        "replacement_types_to_process = ['SYMBOL', 'ACRONYM', 'NAME']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fc017936",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "import re\n",
        "\n",
        "\n",
        "currency_identifiers = ['EURO', 'EUR', 'USD', '$','€','£']\n",
        "currency_pattern = '|'.join([re.escape(str(identifier)) for identifier in currency_identifiers])\n",
        "\n",
        "# Load and filter the FinanceMTEB/financial_phrasebank dataset ---\n",
        "dataset_name = \"FinanceMTEB/financial_phrasebank\"\n",
        "print(f\"Loading dataset: {dataset_name}\")\n",
        "ds_fin = load_dataset(dataset_name)\n",
        "\n",
        "filtered_ds_fin = {}\n",
        "for split_name, dataset_split in ds_fin.items():\n",
        "    if split_name == 'train':\n",
        "        print(f\"Applying currency pattern filter for split: {split_name}\")\n",
        "        filtered_split = dataset_split.filter(lambda example: bool(re.search(currency_pattern, example['text'])))\n",
        "        filtered_ds_fin[split_name] = filtered_split\n",
        "    else:\n",
        "        print(f\"Applying currency pattern filter for split: {split_name}\")\n",
        "        filtered_split = dataset_split.filter(lambda example: bool(re.search(currency_pattern, example['text'])))\n",
        "        filtered_ds_fin[split_name] = filtered_split\n",
        "\n",
        "original_train_texts = filtered_ds_fin['train']['text']\n",
        "original_train_labels = filtered_ds_fin['train']['label']\n",
        "original_test_texts = filtered_ds_fin['test']['text']\n",
        "original_test_labels = filtered_ds_fin['test']['label']\n",
        "\n",
        "compiled_currency_pattern = re.compile(currency_pattern, flags=re.IGNORECASE)\n",
        "\n",
        "new_test_texts = []\n",
        "new_test_labels = []\n",
        "\n",
        "\n",
        "substring_to_remove = \"lemiste City is the environment\"\n",
        "for i, text in enumerate(original_test_texts):\n",
        "\n",
        "    if substring_to_remove in text:\n",
        "        continue\n",
        "\n",
        "    found_currencies = re.findall(compiled_currency_pattern, text)\n",
        "    if found_currencies:\n",
        "        unique_found_currencies = set(found_currencies)\n",
        "        if len(unique_found_currencies) == 1:\n",
        "            new_test_texts.append(text)\n",
        "            new_test_labels.append(original_test_labels[i])\n",
        "test_texts = new_test_texts[0:10]\n",
        "test_labels = new_test_labels[0:10]\n",
        "train_texts = original_train_texts\n",
        "train_labels = original_train_labels\n",
        "\n",
        "print(f\"Number of test samples after filtering for single currency mentions: {len(test_texts)}\")\n",
        "\n",
        "print('test_texts ')\n",
        "print(test_texts)\n",
        "\n",
        "\n",
        "# \"ProsusAI/finbert\"\n",
        "print(sorted(target_models))\n",
        "\n",
        "\n",
        "# \"mixedbread-ai/mxbai-embed-large-v1\"\n",
        "# Define label_map for display\n",
        "label_map = {0: 'Negative', 1: 'Neutral', 2: 'Positive'}\n",
        "sentiment_to_numerical = {'Negative': -1, 'Neutral': 0, 'Positive': 1}\n",
        "\n",
        "output_dir = 'task_financial_phrasebank/\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "\n",
        "for current_replacement_type in replacement_types_to_process:\n",
        "    print(f\"\\n--- Processing Replacement Type: {current_replacement_type} ---\")\n",
        "\n",
        "    current_target_replacement_strings = []\n",
        "    if current_replacement_type == 'SYMBOL':\n",
        "        current_target_replacement_strings = list(set(currency_symbol_dict.values()))\n",
        "    elif current_replacement_type == 'NAME':\n",
        "        current_target_replacement_strings = list(currency_name_dict.values())\n",
        "        current_target_replacement_strings = [\" \" + v + \" \" for v in current_target_replacement_strings]\n",
        "    elif current_replacement_type == 'ACRONYM':\n",
        "        current_target_replacement_strings = list(set(currency_symbol_dict.keys()))\n",
        "\n",
        "    all_exhaustive_analysis_results = [] # Reset for each replacement type\n",
        "\n",
        "    for model_name in target_models:\n",
        "        print(f\"--- Evaluating model: {model_name} for replacement type {current_replacement_type} ---\")\n",
        "\n",
        "        try:\n",
        "\n",
        "            if model_name=='ProsusAI/finbert':\n",
        "                embedding_model = None\n",
        "                print('model_name', model_name)\n",
        "            else:\n",
        "              embedding_model = SentenceTransformer(model_name, device=device, trust_remote_code=True)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {model_name}: {e}. Skipping this model.\")\n",
        "            continue\n",
        "\n",
        "        train_embeddings = np.array(encode_text(train_texts[:], model_name, embedding_model)).squeeze()\n",
        "        test_embeddings = np.array(encode_text(test_texts[:], model_name, embedding_model)).squeeze()\n",
        "\n",
        "        print('train_embeddings', train_embeddings.shape)\n",
        "\n",
        "        logistic_model = LogisticRegression(max_iter=1000)\n",
        "        logistic_model.fit(train_embeddings, train_labels)\n",
        "\n",
        "        model_exhaustive_summary = {\n",
        "            'model_name': model_name,\n",
        "            'replacement_impact': {}\n",
        "        }\n",
        "\n",
        "        for replacement_str in current_target_replacement_strings:\n",
        "            impact_changes = analyze_currency_impact_exhaustive(\n",
        "                logistic_model, model_name, embedding_model, test_texts, test_labels, test_embeddings, currency_pattern, replacement_str\n",
        "            )\n",
        "            model_exhaustive_summary['replacement_impact'][replacement_str] = impact_changes\n",
        "\n",
        "        all_exhaustive_analysis_results.append(model_exhaustive_summary)\n",
        "\n",
        "    for model_result in all_exhaustive_analysis_results:\n",
        "        model_name_for_save = model_result['model_name']\n",
        "        model_specific_impact_data = []\n",
        "        for replacement_str, impact_list in model_result['replacement_impact'].items():\n",
        "            for item in impact_list:\n",
        "                item_copy = item.copy()\n",
        "                item_copy['model_name'] = model_name_for_save\n",
        "                item_copy['replacement_string'] = replacement_str\n",
        "                model_specific_impact_data.append(item_copy)\n",
        "\n",
        "        if model_specific_impact_data:\n",
        "            df_model_specific = pd.DataFrame(model_specific_impact_data)\n",
        "            clean_model_name = model_name_for_save.replace('/', '_').replace('-', '_')\n",
        "            file_name = f'comprehensive_impact_df_task_FinPhrase_{current_replacement_type}_{clean_model_name}.pkl'\n",
        "            file_path_save = os.path.join(output_dir, file_name)\n",
        "            df_model_specific.to_pickle(file_path_save)\n",
        "            print(f\"DataFrame for model '{model_name_for_save}' and replacement type '{current_replacement_type}' saved to '{file_path_save}'\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RUU6wIDhwUi"
      },
      "outputs": [],
      "source": [
        "\n",
        "target_models = [ \"Qwen/Qwen3-Embedding-0.6B\",\"google/embeddinggemma-300M\", \"ProsusAI/finbert\",\"FinLang/finance-embeddings-investopedia\",\"intfloat/multilingual-e5-large\", \"intfloat/multilingual-e5-large-instruct\",\"Alibaba-NLP/gte-large-en-v1.5\",\"Alibaba-NLP/gte-multilingual-base\",\\\n",
        "\n",
        "                            \"jinaai/jina-embeddings-v2-base-en\",\"BAAI/bge-m3\",\"Snowflake/snowflake-arctic-embed-m-v1.5\",\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\",\"sentence-transformers/all-mpnet-base-v2\",\\\n",
        "\n",
        "                            ]\n",
        "#\"\",\"Alibaba-NLP/gte-Qwen2-1.5B-instruct\",,]\n",
        "\n",
        "target_models+=[\"sentence-transformers/LaBSE\"]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDqhFAn3E1Yk"
      },
      "outputs": [],
      "source": [
        "sorted(target_models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mq2MsWE7jbYq"
      },
      "outputs": [],
      "source": [
        "len(target_models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVmeU3RbvCTN"
      },
      "outputs": [],
      "source": [
        "# --- Step 1: Regenerate and save comprehensive_impact_df for each replacement type ---\n",
        "replacement_types_to_process = ['SYMBOL', 'ACRONYM', 'NAME']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kki7AFbnjdlI"
      },
      "outputs": [],
      "source": [
        "# output_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YAhZ68btPqk"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load and combine all comprehensive_impact_df files\n",
        "all_comprehensive_impact_dfs = []\n",
        "for replacement_type_load in replacement_types_to_process:\n",
        "    for model_name_load in target_models: # Loop through models again to load model-specific files\n",
        "        clean_model_name = model_name_load.replace('/', '_').replace('-', '_')\n",
        "        file_path_load = os.path.join(output_dir, f'comprehensive_impact_df_task_FinPhrase_{replacement_type_load}_{clean_model_name}.pkl')\n",
        "        try:\n",
        "            df_temp = pd.read_pickle(file_path_load)\n",
        "            df_temp['replacement_type'] = replacement_type_load\n",
        "            # 'model_name' column should already be present in df_temp from saving\n",
        "            all_comprehensive_impact_dfs.append(df_temp)\n",
        "            print(f\"Loaded {replacement_type_load} data for model {model_name_load}.\")\n",
        "        except FileNotFoundError:\n",
        "            print(f\"No data found for model {model_name_load} and replacement type {replacement_type_load}. Skipping.\")\n",
        "\n",
        "combined_impact_df = pd.concat(all_comprehensive_impact_dfs, ignore_index=True)\n",
        "print(\"\\nCombined DataFrame 'combined_impact_df' created.\")\n",
        "\n",
        "# Convert numerical labels to string names and vice versa\n",
        "combined_impact_df['original_prediction'] = combined_impact_df['original_prediction'].map(label_map)\n",
        "combined_impact_df['modified_prediction'] = combined_impact_df['modified_prediction'].map(label_map)\n",
        "combined_impact_df['true_label'] = combined_impact_df['true_label'].map(label_map)\n",
        "\n",
        "combined_impact_df['numerical_modified_prediction'] = combined_impact_df['modified_prediction'].map(sentiment_to_numerical)\n",
        "combined_impact_df['numerical_true_label'] = combined_impact_df['true_label'].map(sentiment_to_numerical)\n",
        "print(\"Labels converted to string and numerical formats in combined_impact_df.\")\n",
        "\n",
        "#  Calculate metrics_df including macro_precision\n",
        "metrics_df = combined_impact_df.groupby(['model_name', 'replacement_string']).apply(calculate_metrics).reset_index()\n",
        "\n",
        "print(\"\\nMetrics DataFrame 'metrics_df' recreated successfully, including macro_precision.\")\n",
        "display(metrics_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nos8Nd6JYmvD"
      },
      "outputs": [],
      "source": [
        "# all_exhaustive_analysis_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGcX1cNqqQkC"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.max_colwidth', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVisHy0ujhaN"
      },
      "outputs": [],
      "source": [
        "\n",
        "output_dir = '/outputs/Classification_Exp/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3JAFGd8MY8P"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "all_comprehensive_impact_dfs = []\n",
        "replacement_types_to_load = ['SYMBOL', 'ACRONYM', 'NAME']\n",
        "\n",
        "\n",
        "for REPLACEMENT_TYPE in replacement_types_to_load:\n",
        "    for model_name_load in target_models:\n",
        "        clean_model_name = model_name_load.replace('/', '_').replace('-', '_')\n",
        "        print('clean_model_name', clean_model_name)\n",
        "        file_path = os.path.join(output_dir, f'comprehensive_impact_df_task_FinPhrase_{REPLACEMENT_TYPE}_{clean_model_name}.pkl')\n",
        "        try:\n",
        "            df_temp = pd.read_pickle(file_path)\n",
        "            df_temp['replacement_type'] = REPLACEMENT_TYPE\n",
        "            all_comprehensive_impact_dfs.append(df_temp)\n",
        "            print(f\"DataFrame 'comprehensive_impact_df_task_FinPhrase_{REPLACEMENT_TYPE}_{clean_model_name}.pkl' loaded successfully.\")\n",
        "        except FileNotFoundError:\n",
        "            print(f\"No data found for model {model_name_load} and replacement type {REPLACEMENT_TYPE}. Skipping.\")\n",
        "        except EOFError:\n",
        "            print(f\"EOFError: File '{file_path}' is empty or corrupted. Skipping.\")\n",
        "        except Exception as e:\n",
        "            print(f\"An unexpected error occurred while loading '{file_path}': {e}. Skipping.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4a40178e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define label_map here to ensure it's available\n",
        "label_map = {0: 'Negative', 1: 'Neutral', 2: 'Positive'}\n",
        "\n",
        "\n",
        "combined_impact_df = pd.concat(all_comprehensive_impact_dfs, ignore_index=True)\n",
        "\n",
        "# Convert numerical labels to string names using label_map\n",
        "combined_impact_df['original_prediction'] = combined_impact_df['original_prediction'].map(label_map)\n",
        "combined_impact_df['modified_prediction'] = combined_impact_df['modified_prediction'].map(label_map)\n",
        "combined_impact_df['true_label'] = combined_impact_df['true_label'].map(label_map)\n",
        "\n",
        "print(\"Combined DataFrame 'combined_impact_df' created and labels converted successfully.\")\n",
        "display(combined_impact_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1101c653"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires mapping string sentiment labels to numerical values and adding these as new columns to `combined_impact_df`. I will first define the mapping dictionary and then apply it to the specified columns. Finally, I'll display the head of the DataFrame to show the changes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6d5e990e"
      },
      "outputs": [],
      "source": [
        "sentiment_to_numerical = {'Negative': -1, 'Neutral': 0, 'Positive': 1}\n",
        "\n",
        "combined_impact_df['numerical_modified_prediction'] = combined_impact_df['modified_prediction'].map(sentiment_to_numerical)\n",
        "combined_impact_df['numerical_true_label'] = combined_impact_df['true_label'].map(sentiment_to_numerical)\n",
        "\n",
        "print(\"Numerical sentiment columns added to combined_impact_df.\")\n",
        "display(combined_impact_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxPFIi9KcUIM"
      },
      "outputs": [],
      "source": [
        "combined_impact_df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXNUzF39cXWV"
      },
      "outputs": [],
      "source": [
        "combined_impact_df['model_name'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRJs_F8xcXSe"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import entropy\n",
        "import numpy as np\n",
        "\n",
        "def calculate_prediction_entropy(predictions_series):\n",
        "    \"\"\"\n",
        "    Calculates the entropy of a series of predictions.\n",
        "    Args:\n",
        "        predictions_series (pd.Series): A series of categorical predictions (e.g., 'Positive', 'Neutral', 'Negative').\n",
        "    Returns:\n",
        "        float: The entropy of the prediction distribution.\n",
        "    \"\"\"\n",
        "    # Convert predictions to a probability distribution\n",
        "    prob_dist = predictions_series.value_counts(normalize=True)\n",
        "    # Calculate entropy\n",
        "    return entropy(prob_dist)\n",
        "\n",
        "# Group by model_name and original_text, then apply the entropy calculation\n",
        "entropy_per_text_per_model_df = combined_impact_df.groupby(['model_name', 'original_text'])['modified_prediction'].apply(calculate_prediction_entropy).reset_index()\n",
        "entropy_per_text_per_model_df.rename(columns={'modified_prediction': 'entropy'}, inplace=True)\n",
        "\n",
        "print(\"DataFrame 'entropy_per_text_per_model_df' created successfully.\")\n",
        "display(entropy_per_text_per_model_df.head())\n",
        "\n",
        "\n",
        "\n",
        "# Calculate mean, median, standard deviation, min, max, and count of zero entropy for each model\n",
        "model_entropy_summary = entropy_per_text_per_model_df.groupby('model_name')['entropy'].agg([\n",
        "    'mean', 'median', 'std', 'min', 'max',\n",
        "    ('q25', lambda x: x.quantile(0.25)),\n",
        "    ('q75', lambda x: x.quantile(0.75)),\n",
        "    ('zero_entropy_count', lambda x: (x == 0).sum()),\n",
        "    ('total_samples', 'count'),\n",
        "    ('non_zero_entropy_samples', lambda x: (x > 0).sum())\n",
        "]).reset_index()\n",
        "model_entropy_summary.rename(columns={'mean': 'mean_entropy', 'median': 'median_entropy', 'std': 'std_dev_entropy', 'min': 'min_entropy', 'max': 'max_entropy'}, inplace=True)\n",
        "\n",
        "print(\"Mean, median, std dev, min, max, q25, q75, zero entropy count, total samples, and non-zero entropy samples calculated for each model:\")\n",
        "display(model_entropy_summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDMuqOSRcXOI"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Get unique model names\n",
        "model_names = entropy_per_text_per_model_df['model_name'].unique()\n",
        "\n",
        "for model_name in model_names:\n",
        "    model_entropy_data = entropy_per_text_per_model_df[entropy_per_text_per_model_df['model_name'] == model_name]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.histplot(model_entropy_data['entropy'], bins=30, kde=True)\n",
        "    plt.title(f'Distribution of Entropy for Modified Predictions - Model: {model_name}')\n",
        "    plt.xlabel('Entropy')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "print(\"Histograms of entropy distribution for each model generated successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVPcui1KcXLI"
      },
      "outputs": [],
      "source": [
        "!pip install seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLU3YTqZkOJv"
      },
      "outputs": [],
      "source": [
        "output_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYkHvd1XnOyd"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import entropy\n",
        "import numpy as np\n",
        "\n",
        "def calculate_prediction_entropy(predictions_series):\n",
        "    \"\"\"\n",
        "    Calculates the entropy of a series of predictions.\n",
        "    Args:\n",
        "        predictions_series (pd.Series): A series of categorical predictions (e.g., 'Positive', 'Neutral', 'Negative').\n",
        "    Returns:\n",
        "        float: The entropy of the prediction distribution.\n",
        "    \"\"\"\n",
        "    # Convert predictions to a probability distribution\n",
        "    prob_dist = predictions_series.value_counts(normalize=True)\n",
        "    # Calculate entropy\n",
        "    return entropy(prob_dist)\n",
        "\n",
        "# Group by model_name and original_text, then apply the entropy calculation\n",
        "entropy_per_text_per_model_df = combined_impact_df.groupby(['model_name', 'original_text'])['modified_prediction'].apply(calculate_prediction_entropy).reset_index()\n",
        "entropy_per_text_per_model_df.rename(columns={'modified_prediction': 'entropy'}, inplace=True)\n",
        "\n",
        "print(\"DataFrame 'entropy_per_text_per_model_df' created successfully.\")\n",
        "display(entropy_per_text_per_model_df.head())\n",
        "\n",
        "\n",
        "\n",
        "# Calculate mean, median, standard deviation, min, max, and count of zero entropy for each model\n",
        "model_entropy_summary = entropy_per_text_per_model_df.groupby('model_name')['entropy'].agg([\n",
        "    'mean', 'median', 'std', 'min', 'max',\n",
        "    ('q25', lambda x: x.quantile(0.25)),\n",
        "    ('q75', lambda x: x.quantile(0.75)),\n",
        "    ('zero_entropy_count', lambda x: (x == 0).sum()),\n",
        "    ('total_samples', 'count'),\n",
        "    ('non_zero_entropy_samples', lambda x: (x > 0).sum())\n",
        "]).reset_index()\n",
        "model_entropy_summary.rename(columns={'mean': 'mean_entropy', 'median': 'median_entropy', 'std': 'std_dev_entropy', 'min': 'min_entropy', 'max': 'max_entropy'}, inplace=True)\n",
        "\n",
        "print(\"Mean, median, std dev, min, max, q25, q75, zero entropy count, total samples, and non-zero entropy samples calculated for each model:\")\n",
        "display(model_entropy_summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qO5gUaNKvv7R"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "df_plot = entropy_per_text_per_model_df.copy()\n",
        "df_plot['model_name_clean'] = df_plot['model_name'].apply(lambda x: x.split('/')[-1])\n",
        "order = df_plot.groupby('model_name_clean')['entropy'].median().sort_values().index\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "sns.set_context(\"poster\")\n",
        "plt.figure(figsize=(20, 14))\n",
        "\n",
        "ax = sns.boxplot(\n",
        "    x='entropy',\n",
        "    y='model_name_clean',\n",
        "    data=df_plot,\n",
        "    order=order,\n",
        "    palette='viridis',\n",
        "    width=0.6,\n",
        "    linewidth=3, # Thicker lines for the boxes\n",
        "    showfliers=True,\n",
        "    flierprops={\"marker\": \"o\", \"markersize\": 5, \"alpha\": 0.2, \"markerfacecolor\": \"gray\"}\n",
        ")\n",
        "\n",
        "sns.pointplot(\n",
        "    x='entropy',\n",
        "    y='model_name_clean',\n",
        "    data=df_plot,\n",
        "    order=order,\n",
        "    join=False,\n",
        "    color='black',\n",
        "    markers='D',\n",
        "    scale=1.2,\n",
        "    errorbar='sd',\n",
        "    capsize=0.15,\n",
        "    errwidth=4 # Thick error bars\n",
        ")\n",
        "\n",
        "plt.suptitle('Distribution of Sentiment Prediction Entropy Across Models',\n",
        "          fontsize=26, fontweight='black', y=0.95)\n",
        "\n",
        "plt.xlabel('Prediction Entropy Score',\n",
        "           fontsize=32, fontweight='bold', labelpad=25)\n",
        "\n",
        "plt.ylabel('',\n",
        "           fontsize=32, fontweight='bold', labelpad=0)\n",
        "\n",
        "plt.yticks(fontsize=24, fontweight='bold')\n",
        "plt.xticks(fontsize=24, fontweight='bold')\n",
        "sns.despine(left=True)\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.5)\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.98])\n",
        "\n",
        "plt.savefig(f\"{output_dir}/model_entropy_sentiment_plot.pdf\",\n",
        "            format=\"pdf\", dpi=300, bbox_inches='tight')\n",
        "\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPEgY29eHjVz"
      },
      "outputs": [],
      "source": [
        "s# entropy_per_text_per_model_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7efc879a"
      },
      "source": [
        "## Calculate Prediction Counts per Model, Currency, and Sentiment\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ee2f9bd9"
      },
      "outputs": [],
      "source": [
        "prediction_counts_df = combined_impact_df.groupby(['model_name', 'replacement_string', 'modified_prediction']).size().reset_index(name='count')\n",
        "\n",
        "print(\"DataFrame 'prediction_counts_df' created successfully.\")\n",
        "display(prediction_counts_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "751479e1"
      },
      "outputs": [],
      "source": [
        "positive_predictions_per_currency_per_model_df = prediction_counts_df[prediction_counts_df['modified_prediction'] == 'Positive'].copy()\n",
        "negative_predictions_per_currency_per_model_df = prediction_counts_df[prediction_counts_df['modified_prediction'] == 'Negative'].copy()\n",
        "neutral_predictions_per_currency_per_model_df = prediction_counts_df[prediction_counts_df['modified_prediction'] == 'Neutral'].copy()\n",
        "\n",
        "print(\"Separated prediction counts into sentiment-specific DataFrames.\")\n",
        "display(positive_predictions_per_currency_per_model_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8049c713"
      },
      "outputs": [],
      "source": [
        "k = 5 # Number of top/bottom currencies to display\n",
        "\n",
        "# Get unique model names\n",
        "model_names = prediction_counts_df['model_name'].unique()\n",
        "\n",
        "for model_name in model_names:\n",
        "    print(f\"\\n--- Model: {model_name} ---\")\n",
        "\n",
        "    # Positive Predictions\n",
        "    model_df = positive_predictions_per_currency_per_model_df[positive_predictions_per_currency_per_model_df['model_name'] == model_name].copy()\n",
        "    model_df = model_df.sort_values(by='count', ascending=False).rename(columns={'count': 'positive_prediction_count'})\n",
        "\n",
        "    print(f\"\\nTop {k} Positive Predictions for {model_name}:\")\n",
        "    top_k = model_df.head(k).drop(columns=['model_name', 'modified_prediction'])\n",
        "    display(top_k)\n",
        "\n",
        "    print(f\"Bottom {k} Positive Predictions for {model_name}:\")\n",
        "    bottom_k = model_df.tail(k).drop(columns=['model_name', 'modified_prediction'])\n",
        "    display(bottom_k)\n",
        "\n",
        "    # Negative Predictions\n",
        "    model_df_negative = negative_predictions_per_currency_per_model_df[negative_predictions_per_currency_per_model_df['model_name'] == model_name].copy()\n",
        "    model_df_negative = model_df_negative.sort_values(by='count', ascending=False).rename(columns={'count': 'negative_prediction_count'})\n",
        "\n",
        "    print(f\"\\nTop {k} Negative Predictions for {model_name}:\")\n",
        "    top_k_negative = model_df_negative.head(k).drop(columns=['model_name', 'modified_prediction'])\n",
        "    display(top_k_negative)\n",
        "\n",
        "    print(f\"Bottom {k} Negative Predictions for {model_name}:\")\n",
        "    bottom_k_negative = model_df_negative.tail(k).drop(columns=['model_name', 'modified_prediction'])\n",
        "    display(bottom_k_negative)\n",
        "\n",
        "    # Neutral Predictions\n",
        "    model_df_neutral = neutral_predictions_per_currency_per_model_df[neutral_predictions_per_currency_per_model_df['model_name'] == model_name].copy()\n",
        "    model_df_neutral = model_df_neutral.sort_values(by='count', ascending=False).rename(columns={'count': 'neutral_prediction_count'})\n",
        "\n",
        "    print(f\"\\nTop {k} Neutral Predictions for {model_name}:\")\n",
        "    top_k_neutral = model_df_neutral.head(k).drop(columns=['model_name', 'modified_prediction'])\n",
        "    display(top_k_neutral)\n",
        "\n",
        "    print(f\"Bottom {k} Neutral Predictions for {model_name}:\")\n",
        "    bottom_k_neutral = model_df_neutral.tail(k).drop(columns=['model_name', 'modified_prediction'])\n",
        "    display(bottom_k_neutral)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8734a55"
      },
      "outputs": [],
      "source": [
        "negative_model_stats = negative_predictions_per_currency_per_model_df.groupby('model_name')['count'].describe()\n",
        "print(\"Descriptive statistics for negative prediction counts per model:\")\n",
        "display(negative_model_stats)\n",
        "\n",
        "\n",
        "\n",
        "positive_model_stats = positive_predictions_per_currency_per_model_df.groupby('model_name')['count'].describe()\n",
        "print(\"Descriptive statistics for positive_model_stats prediction counts per model:\")\n",
        "display(positive_model_stats)\n",
        "\n",
        "\n",
        "\n",
        "neutral_model_stats = neutral_predictions_per_currency_per_model_df.groupby('model_name')['count'].describe()\n",
        "print(\"Descriptive statistics for neutral_model_stats prediction counts per model:\")\n",
        "display(neutral_model_stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWJwM8cc5VYW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69d2384d"
      },
      "source": [
        "**Reasoning**:\n",
        "The next step is to generate a box plot to visualize the distribution of `negative_prediction_count` for each `model_name` using the `negative_predictions_per_currency_per_model_df` DataFrame, as specified in the task.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RNUeWECGGpW"
      },
      "outputs": [],
      "source": [
        "model_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63f88319"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "# --- STYLE SETTINGS ---\n",
        "sns.set_style(\"whitegrid\")\n",
        "# 'poster' is the largest context, making lines and labels naturally massive\n",
        "sns.set_context(\"poster\")\n",
        "\n",
        "# output_dir = \"sentiment_distributions\"\n",
        "output_individual_plots = output_dir + '/sentiment_plots_normal/'\n",
        "os.makedirs(output_individual_plots, exist_ok=True)\n",
        "\n",
        "model_names = prediction_counts_df['model_name'].unique()\n",
        "\n",
        "for model_name in model_names:\n",
        "    clean_name = model_name.split('/')[-1]\n",
        "    model_data = prediction_counts_df[prediction_counts_df['model_name'] == model_name]\n",
        "\n",
        "    # Increased figure height slightly to accommodate larger fonts\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(24, 10), sharey=True)\n",
        "\n",
        "    # MASSIVE MAIN TITLE\n",
        "    fig.suptitle(f'Sentiment Label Distribution Density for {clean_name}',\n",
        "                 fontsize=32, fontweight='black', y=1.01)\n",
        "\n",
        "    sentiments = [\n",
        "        ('Positive', '#3498db', axes[0]),\n",
        "        ('Neutral', '#2ecc71', axes[1]),\n",
        "        ('Negative', '#e74c3c', axes[2])\n",
        "    ]\n",
        "\n",
        "    for label, col, ax in sentiments:\n",
        "        sentiment_data = model_data[model_data['modified_prediction'] == label]\n",
        "\n",
        "        if not sentiment_data.empty:\n",
        "            sns.histplot(x='count', data=sentiment_data, kde=True, ax=ax,\n",
        "                         color=col, alpha=0.7, edgecolor='white', linewidth=3)\n",
        "\n",
        "            # Subplot titles (Positive, Neutral, Negative)\n",
        "            ax.set_title(label.upper(), fontsize=22, fontweight='bold', pad=20)\n",
        "        else:\n",
        "            ax.set_title(f'{label.upper()} (NO DATA)', fontsize=22, fontweight='bold', color='gray')\n",
        "            ax.text(0.5, 0.5, 'No Data', ha='center', va='center',\n",
        "                    transform=ax.transAxes, fontweight='bold', fontsize=24)\n",
        "\n",
        "        # Clear local labels to use the global ones\n",
        "        ax.set_xlabel('')\n",
        "        ax.set_ylabel('')\n",
        "\n",
        "        # TICKS: Larger and Bolder numbers\n",
        "        ax.tick_params(axis='both', labelsize=24, pad=5)\n",
        "        plt.setp(ax.get_xticklabels(), fontweight='bold')\n",
        "        plt.setp(ax.get_yticklabels(), fontweight='bold')\n",
        "\n",
        "    # --- ADD MASSIVE GLOBAL LABELS (TIGHTENED GAP) ---\n",
        "\n",
        "    # Common X-axis label\n",
        "    fig.supxlabel('Label Agreement (How many times the model picked this label per text)',\n",
        "                  fontsize=30, fontweight='bold', y=0.05)\n",
        "\n",
        "    # Common Y-axis label\n",
        "    fig.supylabel('Number of Unique Sentences',\n",
        "                  fontsize=30, fontweight='bold', x=0.01)\n",
        "\n",
        "    # Adjusting layout for large fonts\n",
        "    # rect=[left, bottom, right, top]\n",
        "    sns.despine()\n",
        "    plt.tight_layout(rect=[0.05, 0.1, 1, 0.95])\n",
        "\n",
        "    safe_name = clean_name.replace('.', '_').replace('-', '_')\n",
        "    file_path = f\"{output_individual_plots}/stability_{safe_name}.pdf\"\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.savefig(file_path, format=\"pdf\", dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "print(f\"\\n✅ All high-visibility plots saved to '{output_dir}'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgS0xAZB6YFO"
      },
      "outputs": [],
      "source": [
        "output_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34868335"
      },
      "source": [
        "## Calculate Overall Sentiment Proportions per Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fd84377"
      },
      "outputs": [],
      "source": [
        "aggregated_predictions_per_model = prediction_counts_df.groupby(['model_name', 'modified_prediction'])['count'].sum().reset_index()\n",
        "\n",
        "pivoted_predictions_df = aggregated_predictions_per_model.pivot(index='model_name', columns='modified_prediction', values='count').fillna(0)\n",
        "pivoted_predictions_df.columns.name = None\n",
        "\n",
        "pivoted_predictions_df['Total Predictions'] = pivoted_predictions_df['Positive'] + pivoted_predictions_df['Neutral'] + pivoted_predictions_df['Negative']\n",
        "\n",
        "overall_sentiment_proportions = pivoted_predictions_df.copy()\n",
        "overall_sentiment_proportions['Positive_Proportion'] = overall_sentiment_proportions['Positive'] / overall_sentiment_proportions['Total Predictions']\n",
        "overall_sentiment_proportions['Neutral_Proportion'] = overall_sentiment_proportions['Neutral'] / overall_sentiment_proportions['Total Predictions']\n",
        "overall_sentiment_proportions['Negative_Proportion'] = overall_sentiment_proportions['Negative'] / overall_sentiment_proportions['Total Predictions']\n",
        "\n",
        "print(\"DataFrame 'overall_sentiment_proportions' created successfully with sentiment proportions.\")\n",
        "display(overall_sentiment_proportions.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47ddbfee"
      },
      "outputs": [],
      "source": [
        "grouped_predictions = prediction_counts_df.groupby(['model_name', 'replacement_string', 'modified_prediction'])['count'].sum().reset_index()\n",
        "\n",
        "currency_predictions_pivot_df = grouped_predictions.pivot_table(\n",
        "    index=['model_name', 'replacement_string'],\n",
        "    columns='modified_prediction',\n",
        "    values='count'\n",
        ").fillna(0).reset_index()\n",
        "\n",
        "currency_predictions_pivot_df['Total_Predictions'] = currency_predictions_pivot_df['Positive'] + \\\n",
        "                                            currency_predictions_pivot_df['Neutral'] + \\\n",
        "                                            currency_predictions_pivot_df['Negative']\n",
        "\n",
        "currency_predictions_pivot_df['Positive_Proportion'] = currency_predictions_pivot_df['Positive'] / currency_predictions_pivot_df['Total_Predictions']\n",
        "# currency_predictions_pivot_df['Neutral_Proportion'] = currency_predictions_pivot_df['Neutral'] / currency_predictions_pivot_df['Total_Predictions']\n",
        "# currency_predictions_pivot_df['Negative_Proportion'] = currency_predictions_pivot_df['Negative'] / currency_predictions_pivot_df['Total_Predictions']\n",
        "\n",
        "currency_sentiment_proportions = currency_predictions_pivot_df.copy()\n",
        "\n",
        "print(\"DataFrame 'currency_sentiment_proportions' created successfully with currency-specific sentiment proportions.\")\n",
        "display(currency_sentiment_proportions.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1a607a0d"
      },
      "outputs": [],
      "source": [
        "bias_df = pd.merge(currency_sentiment_proportions, overall_sentiment_proportions, on='model_name', suffixes=('_currency', '_overall'))\n",
        "\n",
        "bias_df['Positive_Bias'] = bias_df['Positive_Proportion_currency'] - bias_df['Positive_Proportion_overall']\n",
        "# bias_df['Neutral_Bias'] = bias_df['Neutral_Proportion_currency'] - bias_df['Neutral_Proportion_overall']\n",
        "# bias_df['Negative_Bias'] = bias_df['Negative_Proportion_currency'] - bias_df['Negative_Proportion_overall']\n",
        "\n",
        "# bias_df['Neutral_Bias'] = bias_df['Neutral_Proportion_currency'] - bias_df['Neutral_Proportion_overall']\n",
        "# bias_df['Negative_Bias'] = bias_df['Negative_Proportion_currency'] - bias_df['Negative_Proportion_overall']\n",
        "\n",
        "\n",
        "\n",
        "print(\"DataFrame 'bias_df' created successfully with bias scores.\")\n",
        "display(bias_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fa86c192"
      },
      "outputs": [],
      "source": [
        "k = 5 # Number of top/bottom currencies to display\n",
        "\n",
        "model_names = bias_df['model_name'].unique()\n",
        "\n",
        "for model_name in model_names:\n",
        "    print(f\"\\n--- Identifying Most Biased Currencies for Model: {model_name} ---\")\n",
        "    model_bias_df = bias_df[bias_df['model_name'] == model_name]\n",
        "\n",
        "    # Positive Bias\n",
        "    print(f\"\\nTop {k} Positive Bias (most positively biased) for {model_name}:\")\n",
        "    top_positive_bias = model_bias_df.sort_values(by='Positive_Bias', ascending=False).head(k)\n",
        "    display(top_positive_bias[['replacement_string', 'Positive_Bias', 'Positive_Proportion_currency', 'Positive_Proportion_overall']])\n",
        "\n",
        "    print(f\"Bottom {k} Positive Bias (most negatively biased towards positive) for {model_name}:\")\n",
        "    bottom_positive_bias = model_bias_df.sort_values(by='Positive_Bias', ascending=True).head(k)\n",
        "    display(bottom_positive_bias[['replacement_string', 'Positive_Bias', 'Positive_Proportion_currency', 'Positive_Proportion_overall']])\n",
        "\n",
        "    # # Neutral Bias\n",
        "    # print(f\"\\nTop {k} Neutral Bias (most neutral biased) for {model_name}:\")\n",
        "    # top_neutral_bias = model_bias_df.sort_values(by='Neutral_Bias', ascending=False).head(k)\n",
        "    # display(top_neutral_bias[['replacement_string', 'Neutral_Bias', 'Neutral_Proportion_currency', 'Neutral_Proportion_overall']])\n",
        "\n",
        "    # print(f\"Bottom {k} Neutral Bias (most negatively biased towards neutral) for {model_name}:\")\n",
        "    # bottom_neutral_bias = model_bias_df.sort_values(by='Neutral_Bias', ascending=True).head(k)\n",
        "    # display(bottom_neutral_bias[['replacement_string', 'Neutral_Bias', 'Neutral_Proportion_currency', 'Neutral_Proportion_overall']])\n",
        "\n",
        "    # # Negative Bias\n",
        "    # print(f\"\\nTop {k} Negative Bias (most negatively biased) for {model_name}:\")\n",
        "    # top_negative_bias = model_bias_df.sort_values(by='Negative_Bias', ascending=False).head(k)\n",
        "    # display(top_negative_bias[['replacement_string', 'Negative_Bias', 'Negative_Proportion_currency', 'Negative_Proportion_overall']])\n",
        "\n",
        "    # print(f\"Bottom {k} Negative Bias (most positively biased towards negative) for {model_name}:\")\n",
        "    # bottom_negative_bias = model_bias_df.sort_values(by='Negative_Bias', ascending=True).head(k)\n",
        "    # display(bottom_negative_bias[['replacement_string', 'Negative_Bias', 'Negative_Proportion_currency', 'Negative_Proportion_overall']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SECrebNSuyZs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2c4f4c1"
      },
      "outputs": [],
      "source": [
        "bias_df_percentages = bias_df.copy()\n",
        "\n",
        "bias_df_percentages['Positive_Bias_Percentage'] = bias_df_percentages['Positive_Bias'] * 100\n",
        "# bias_df_percentages['Neutral_Bias_Percentage'] = bias_df_percentages['Neutral_Bias'] * 100\n",
        "# bias_df_percentages['Negative_Bias_Percentage'] = bias_df_percentages['Negative_Bias'] * 100\n",
        "\n",
        "print(\"DataFrame 'bias_df_percentages' created with bias scores in percentage points.\")\n",
        "display(bias_df_percentages[['model_name', 'replacement_string', 'Positive_Bias_Percentage']].head())#, 'Neutral_Bias_Percentage', 'Negative_Bias_Percentage']].head())\n",
        "# display(bias_df_percentages[['model_name', 'replacement_string', 'Positive_Bias_Percentage', 'Neutral_Bias_Percentage', 'Negative_Bias_Percentage']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xset6Sf0vIUR"
      },
      "outputs": [],
      "source": [
        "\n",
        "bias_df_percentages = bias_df.copy()\n",
        "\n",
        "bias_df_percentages['Positive_Relative_Change'] = (bias_df_percentages['Positive_Bias'] / bias_df_percentages['Positive_Proportion_overall']) * 100\n",
        "bias_df_percentages.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "print(\"Updated DataFrame 'bias_df_percentages' with neutral and negative bias, and relative percentage changes.\")\n",
        "display(bias_df_percentages[['model_name', 'replacement_string','Positive_Relative_Change']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qbme4Vy7nqQC"
      },
      "outputs": [],
      "source": [
        "bias_df_percentages.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50f8a493"
      },
      "outputs": [],
      "source": [
        "currency_bias_summary = bias_df_percentages.groupby('replacement_string').agg(\n",
        "    mean_positive_relative_change=('Positive_Relative_Change', 'mean'),\n",
        "    std_positive_relative_change=('Positive_Relative_Change', 'std')\n",
        ").reset_index()\n",
        "\n",
        "print(\"DataFrame 'currency_bias_summary' created successfully with mean and standard deviation of positive relative change.\")\n",
        "display(currency_bias_summary.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9a028e2"
      },
      "outputs": [],
      "source": [
        "print(\"\\nTop 5 most positive-biased currencies (highest mean_positive_relative_change):\")\n",
        "top_5_positive_bias = currency_bias_summary.sort_values(by='mean_positive_relative_change', ascending=False).head(5)\n",
        "display(top_5_positive_bias)\n",
        "\n",
        "print(\"\\nTop 5 most negatively-biased currencies (lowest mean_positive_relative_change):\")\n",
        "top_5_negative_bias = currency_bias_summary.sort_values(by='mean_positive_relative_change', ascending=True).head(5)\n",
        "display(top_5_negative_bias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bB_38Hb8l5wx"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Sort the currencies by mean_positive_relative_change for better visualization\n",
        "currency_bias_summary_sorted = currency_bias_summary.sort_values(by='mean_positive_relative_change', ascending=True)\n",
        "\n",
        "# Get the top 10 most negatively-biased (lowest mean_positive_relative_change)\n",
        "bottom_10_biased = currency_bias_summary_sorted.head(10)\n",
        "\n",
        "# Get the top 10 most positive-biased (highest mean_positive_relative_change)\n",
        "top_10_biased = currency_bias_summary_sorted.tail(10)\n",
        "\n",
        "# Combine and sort for plotting\n",
        "plot_data = pd.concat([bottom_10_biased, top_10_biased]).sort_values(by='mean_positive_relative_change', ascending=True)\n",
        "\n",
        "plt.figure(figsize=(16, 10))\n",
        "\n",
        "# Create a colormap that maps values to a diverging palette (e.g., coolwarm)\n",
        "# This helps visualize positive and negative biases effectively\n",
        "norm = plt.Normalize(plot_data['mean_positive_relative_change'].min(),\n",
        "                     plot_data['mean_positive_relative_change'].max())\n",
        "cmap = plt.cm.coolwarm\n",
        "colors = cmap(norm(plot_data['mean_positive_relative_change']))\n",
        "\n",
        "plt.barh(\n",
        "    plot_data['replacement_string'],\n",
        "    plot_data['mean_positive_relative_change'],\n",
        "    xerr=plot_data['std_positive_relative_change'], # Standard deviation as error bars\n",
        "    color=colors, # Apply the diverging color map\n",
        "    edgecolor='black' # Add edge color for better separation\n",
        ")\n",
        "\n",
        "plt.title('Top/Bottom 10 Most Biased Currencies (Mean Positive Relative Change with Std Dev)', fontsize=18, fontweight='bold')\n",
        "plt.xlabel('Mean Positive Relative Change (%)', fontsize=14)\n",
        "plt.ylabel('Currency Replacement String', fontsize=14)\n",
        "plt.xticks(fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c54da367"
      },
      "outputs": [],
      "source": [
        "k = 15\n",
        "top_k_currencies = currency_bias_summary.nlargest(k, 'mean_positive_relative_change')['replacement_string'].tolist()\n",
        "bottom_k_currencies = currency_bias_summary.nsmallest(k, 'mean_positive_relative_change')['replacement_string'].tolist()\n",
        "\n",
        "selected_currencies = list(set(top_k_currencies + bottom_k_currencies))\n",
        "\n",
        "filtered_bias_df_percentages = bias_df_percentages[bias_df_percentages['replacement_string'].isin(selected_currencies)].copy()\n",
        "\n",
        "# Get the order of replacement strings based on their mean_positive_relative_change for consistent plotting\n",
        "sorted_currency_order = currency_bias_summary.set_index('replacement_string').loc[selected_currencies].sort_values(by='mean_positive_relative_change', ascending=False).index.tolist()\n",
        "\n",
        "# Convert replacement_string to a categorical type with the sorted order\n",
        "filtered_bias_df_percentages['replacement_string'] = pd.Categorical(filtered_bias_df_percentages['replacement_string'], categories=sorted_currency_order, ordered=True)\n",
        "\n",
        "# Sort the DataFrame by the categorical order\n",
        "filtered_bias_df_percentages = filtered_bias_df_percentages.sort_values(by='replacement_string').reset_index(drop=True)\n",
        "\n",
        "print(f\"Filtered `bias_df_percentages` to include {len(selected_currencies)} unique currency replacement strings. Shape: {filtered_bias_df_percentages.shape}\")\n",
        "display(filtered_bias_df_percentages.head(20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ajQBXSspRIY"
      },
      "outputs": [],
      "source": [
        "top_k_currencies, bottom_k_currencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jobLVeC8pTSv"
      },
      "outputs": [],
      "source": [
        "# filtered_bias_df_percentages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bebe4fc"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib.font_manager as fm\n",
        "\n",
        "plt.rcParams['font.family'] = 'sans-serif'\n",
        "\n",
        "preferred_fonts = ['Noto Color Emoji', 'Noto Sans CJK JP', 'Noto Sans Display', 'DejaVu Sans', 'Arial Unicode MS', 'Arial']\n",
        "\n",
        "found_font_name = None\n",
        "for font_name in preferred_fonts:\n",
        "    try:\n",
        "        font_path = fm.findfont(fm.FontProperties(family=font_name), fallback_to_default=False)\n",
        "        found_font_name = fm.FontProperties(fname=font_path).get_name()\n",
        "        plt.rcParams['font.sans-serif'] = [found_font_name]\n",
        "        plt.rcParams['axes.unicode_minus'] = False # Fix minus sign for Unicode fonts\n",
        "        print(f\"Using Unicode font: {found_font_name}\")\n",
        "        break\n",
        "    except ValueError:\n",
        "        pass\n",
        "    except UserWarning:\n",
        "        pass\n",
        "\n",
        "if not found_font_name:\n",
        "    print(\"Warning: Could not find a suitable Unicode font. Currency symbols might not display correctly, defaulting to system font.\")\n",
        "    plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial', 'Liberation Sans'] # Fallback list\n",
        "    plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "sns.set_context(\"poster\")\n",
        "\n",
        "plt.figure(figsize=(18, 12))\n",
        "\n",
        "\n",
        "\n",
        "ax = sns.boxplot(\n",
        "    x='Positive_Relative_Change',\n",
        "    y='replacement_string',\n",
        "    data=filtered_bias_df_percentages,\n",
        "    hue='replacement_string',\n",
        "    legend=False,\n",
        "    palette='viridis',\n",
        "    width=0.6,\n",
        "    linewidth=2.5,\n",
        "    whis=0,\n",
        "    showfliers=True,  # Keep outliers visible\n",
        "    # REDUCED markersize here (changed from 7 to 3)\n",
        "    flierprops={\"marker\": \"o\", \"markersize\": 3, \"alpha\": 0.4}\n",
        ")\n",
        "\n",
        "sns.pointplot(\n",
        "    x='Positive_Relative_Change',\n",
        "    y='replacement_string',\n",
        "    data=filtered_bias_df_percentages,\n",
        "    linestyle='none',\n",
        "    color='black',\n",
        "    markers='D',\n",
        "    markersize=15,\n",
        "    errorbar='sd',\n",
        "    capsize=0.15,      # Keeps the SD caps\n",
        "    err_kws={'linewidth': 3}\n",
        ")\n",
        "\n",
        "plt.axvline(x=0, color='crimson', linestyle='-', linewidth=4, zorder=1)\n",
        "plt.axhline(y=k - 0.5, color='black', linestyle=':', linewidth=3, alpha=0.8)\n",
        "\n",
        "plt.text(ax.get_xlim()[1], k - 0.7, f' Top {k} ', va='bottom', ha='right', fontweight='bold', fontsize=16)\n",
        "plt.text(ax.get_xlim()[1], k - 0.3, f' Bottom {k} ', va='top', ha='right', fontweight='bold', fontsize=16)\n",
        "\n",
        "# Apply high-visibility styling\n",
        "plt.title(f'Distribution of Positive Relative Change for Top/Bottom {k} Biased Currencies',\n",
        "          fontsize=30, fontweight='black', pad=30)\n",
        "plt.xlabel('Positive Relative Change (%)', fontsize=24, fontweight='bold', labelpad=20)\n",
        "plt.ylabel('Currency Replacement String', fontsize=24, fontweight='bold', labelpad=20)\n",
        "\n",
        "plt.xticks(fontsize=18, fontweight='bold')\n",
        "plt.yticks(fontsize=18, fontweight='bold')\n",
        "\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
        "sns.despine(left=True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5b64c044"
      },
      "outputs": [],
      "source": [
        "k = 10\n",
        "print(f\"Set k to: {k}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "822c9aed"
      },
      "outputs": [],
      "source": [
        "model_names = bias_df_percentages['model_name'].unique()\n",
        "\n",
        "for model_name in model_names:\n",
        "    print(f\"\\n--- Model: {model_name} ---\")\n",
        "    model_bias_df = bias_df_percentages[bias_df_percentages['model_name'] == model_name].copy()\n",
        "\n",
        "    # Top k most positive-biased currencies\n",
        "    top_k_positive_bias = model_bias_df.sort_values(by='Positive_Relative_Change', ascending=False).head(k)\n",
        "    print(f\"Top {k} most positive-biased currencies for {model_name}:\")\n",
        "    display(top_k_positive_bias[['replacement_string', 'Positive_Relative_Change']].round(2))\n",
        "\n",
        "    # Top k most negatively-biased currencies\n",
        "    bottom_k_negative_bias = model_bias_df.sort_values(by='Positive_Relative_Change', ascending=True).head(k)\n",
        "    print(f\"Top {k} most negatively-biased currencies for {model_name}:\")\n",
        "    display(bottom_k_negative_bias[['replacement_string', 'Positive_Relative_Change']].round(2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5997e61"
      },
      "source": [
        "## Generate Bias Plots per Model:\n",
        "For each unique model, generate a horizontal bar plot showing the top 10 most positive-biased and bottom 10 most negatively-biased currency replacement strings based on their Positive relative change.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dd713ff0"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Ensure output_dir exists\n",
        "# output_dir = './bias_results'\n",
        "os.makedirs(os.path.join(output_dir, 'currency_wise_pos_bias'), exist_ok=True)\n",
        "\n",
        "k = 10\n",
        "\n",
        "model_names = bias_df_percentages['model_name'].unique()\n",
        "\n",
        "for model_name in model_names:\n",
        "    print(f\"\\nGenerating bias plot for model: {model_name}\")\n",
        "\n",
        "    model_bias_df = bias_df_percentages[bias_df_percentages['model_name'] == model_name].copy()\n",
        "\n",
        "    # Identify top and bottom k\n",
        "    top_k_positive_bias = model_bias_df.sort_values(by='Positive_Relative_Change', ascending=False).head(k)\n",
        "    bottom_k_negative_bias = model_bias_df.sort_values(by='Positive_Relative_Change', ascending=True).head(k)\n",
        "\n",
        "    # Combine and sort for the plot\n",
        "    plot_data = pd.concat([top_k_positive_bias, bottom_k_negative_bias])\n",
        "    plot_data = plot_data.sort_values(by='Positive_Relative_Change', ascending=True).reset_index(drop=True)\n",
        "\n",
        "    plt.figure(figsize=(16, 12))\n",
        "\n",
        "    norm = plt.Normalize(plot_data['Positive_Relative_Change'].min(),\n",
        "                         plot_data['Positive_Relative_Change'].max())\n",
        "    cmap = plt.cm.RdBu\n",
        "    colors = cmap(norm(plot_data['Positive_Relative_Change']))\n",
        "\n",
        "    plt.barh(\n",
        "        plot_data['replacement_string'],\n",
        "        plot_data['Positive_Relative_Change'],\n",
        "        color=colors,\n",
        "        edgecolor='black'\n",
        "    )\n",
        "\n",
        "    # --- DOTTED SEPARATION LINE ---\n",
        "    # linestyle=':' creates the dotted effect. ':' is dotted, '--' is dashed.\n",
        "    plt.axhline(y=k - 0.5, color='black', linestyle=':', linewidth=3)\n",
        "\n",
        "    # Optional: Labels to clarify the zones\n",
        "    plt.text(plt.xlim()[1], k - 0.2, f' TOP {k} ', va='bottom', ha='right', fontsize=28, fontweight='bold')\n",
        "    plt.text(plt.xlim()[1], k - 0.8, f' BOTTOM {k} ', va='top', ha='right', fontsize=28, fontweight='bold')\n",
        "\n",
        "    # Vertical reference line\n",
        "    plt.axvline(x=0, color='gray', linestyle='-', linewidth=0.8, alpha=0.5)\n",
        "\n",
        "    clean_model_name = model_name.replace('/', '_').replace('-', '_')\n",
        "\n",
        "    plt.title(f'{clean_model_name}',\n",
        "              fontsize=25, fontweight='bold', pad=20)\n",
        "    plt.xlabel('Positive Relative Change (%)', fontsize=28)\n",
        "    # plt.ylabel('Currency', fontsize=24)\n",
        "    plt.xticks(fontsize=28)\n",
        "    plt.yticks(fontsize=28)\n",
        "    plt.grid(axis='x', linestyle='--', alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save and Show\n",
        "    file_name = f'sent_class_curr_level_bias_plot_{clean_model_name}.pdf'\n",
        "    file_path = os.path.join(output_dir, 'currency_wise_pos_bias', file_name)\n",
        "\n",
        "    plt.savefig(file_path, format='pdf', bbox_inches='tight')\n",
        "    # plt.show()\n",
        "    plt.close()\n",
        "\n",
        "print(f\"\\nAll bias plots for each model saved to '{output_dir}'.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}