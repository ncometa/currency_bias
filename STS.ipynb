{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYlClmTqHBbk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"HF_TOKEN\"] = \"your_token\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWjpYq6brYFS"
      },
      "outputs": [],
      "source": [
        "\n",
        "currency_name_dict = {\n",
        "    'USD': 'United States Dollar',\n",
        "    'INR': 'Indian Rupee',\n",
        "    'EUR': 'Euro',\n",
        "    'GBP': 'British Pound Sterling',\n",
        "    'JPY': 'Japanese Yen',\n",
        "    'CHF': 'Swiss Franc',\n",
        "    'KPW': 'North Korean Won',\n",
        "    'PKR': 'Pakistani Rupee',\n",
        "    'CNY': 'Chinese Yuan',\n",
        "    'AUD': 'Australian Dollar',\n",
        "    'CAD': 'Canadian Dollar',\n",
        "    'MXN': 'Mexican Peso',\n",
        "    'RUB': 'Russian Ruble',\n",
        "    'ZAR': 'South African Rand',\n",
        "    'NGN': 'Nigerian Naira',\n",
        "    'THB': 'Thai Baht',\n",
        "    'VND': 'Vietnamese Dong',\n",
        "    'IDR': 'Indonesian Rupiah',\n",
        "    'KRW': 'South Korean Won',\n",
        "    'PLN': 'Polish Złoty',\n",
        "    'SEK': 'Swedish Krona',\n",
        "    'TRY': 'Turkish Lira',\n",
        "    'BRL': 'Brazilian Real',\n",
        "    'AED': 'United Arab Emirates Dirham',\n",
        "    'SAR': 'Saudi Riyal',\n",
        "    'SCR': 'Seychellois Rupee',\n",
        "    'YER': 'Yemeni Rial',\n",
        "    'SLL': 'Sierra Leonean Leone',\n",
        "    'MWK': 'Malawian Kwacha',\n",
        "    'GHS': 'Ghanaian Cedi',\n",
        "    'UGX': 'Ugandan Shilling',\n",
        "    'TZS': 'Tanzanian Shilling',\n",
        "    'XOF': 'West African CFA Franc',\n",
        "    'DZD': 'Algerian Dinar',\n",
        "    'EGP': 'Egyptian Pound',\n",
        "    'PHP': 'Philippine Peso',\n",
        "    'MYR': 'Malaysian Ringgit',\n",
        "    'LKR': 'Sri Lankan Rupee',\n",
        "    'NPR': 'Nepalese Rupee',\n",
        "    'BDT': 'Bangladeshi Taka',\n",
        "    'OMR': 'Omani Rial',\n",
        "    'SGD': 'Singapore Dollar',\n",
        "\n",
        "    'AFN': 'Afghan Afghani',\n",
        "    'ALL': 'Albanian Lek',\n",
        "    'AMD': 'Armenian Dram',\n",
        "    'AOA': 'Angolan Kwanza',\n",
        "    'ARS': 'Argentine Peso',\n",
        "    'AZN': 'Azerbaijani Manat',\n",
        "    'BAM': 'Bosnia and Herzegovina Convertible Mark',\n",
        "    'BBD': 'Barbadian Dollar',\n",
        "    'BGN': 'Bulgarian Lev',\n",
        "    'BHD': 'Bahraini Dinar',\n",
        "    'BIF': 'Burundian Franc',\n",
        "    'BMD': 'Bermudian Dollar',\n",
        "    'BND': 'Brunei Dollar',\n",
        "    'BOB': 'Bolivian Boliviano',\n",
        "    'BSD': 'Bahamian Dollar',\n",
        "    'BTN': 'Bhutanese Ngultrum',\n",
        "    'BWP': 'Botswana Pula',\n",
        "    'BYN': 'Belarusian Ruble',\n",
        "    'BZD': 'Belize Dollar',\n",
        "    'CDF': 'Congolese Franc',\n",
        "    'CLP': 'Chilean Peso',\n",
        "    'COP': 'Colombian Peso',\n",
        "    'CRC': 'Costa Rican Colón',\n",
        "    'CUP': 'Cuban Peso',\n",
        "    'CVE': 'Cape Verdean Escudo',\n",
        "    'CZK': 'Czech Koruna',\n",
        "    'DJF': 'Djiboutian Franc',\n",
        "    'DKK': 'Danish Krone',\n",
        "    'DOP': 'Dominican Peso',\n",
        "    'ERN': 'Eritrean Nakfa',\n",
        "    'ETB': 'Ethiopian Birr',\n",
        "    'FJD': 'Fijian Dollar',\n",
        "    'GEL': 'Georgian Lari',\n",
        "    'GMD': 'Gambian Dalasi',\n",
        "    'GNF': 'Guinean Franc',\n",
        "    'GTQ': 'Guatemalan Quetzal',\n",
        "    'GYD': 'Guyanese Dollar',\n",
        "    'HKD': 'Hong Kong Dollar',\n",
        "    'HNL': 'Honduran Lempira',\n",
        "    'HTG': 'Haitian Gourde',\n",
        "    'HUF': 'Hungarian Forint',\n",
        "    'ILS': 'Israeli New Shekel',\n",
        "    'IQD': 'Iraqi Dinar',\n",
        "    'IRR': 'Iranian Rial',\n",
        "    'ISK': 'Icelandic Króna',\n",
        "    'JMD': 'Jamaican Dollar',\n",
        "    'JOD': 'Jordanian Dinar',\n",
        "    'KES': 'Kenyan Shilling',\n",
        "    'KGS': 'Kyrgyzstani Som',\n",
        "    'KHR': 'Cambodian Riel',\n",
        "    'KMF': 'Comorian Franc',\n",
        "    'KWD': 'Kuwaiti Dinar',\n",
        "    'KYD': 'Cayman Islands Dollar',\n",
        "    'KZT': 'Kazakhstani Tenge',\n",
        "    'LAK': 'Lao Kip',\n",
        "    'LBP': 'Lebanese Pound',\n",
        "    'LRD': 'Liberian Dollar',\n",
        "    'LSL': 'Lesotho Loti',\n",
        "    'LYD': 'Libyan Dinar',\n",
        "    'MAD': 'Moroccan Dirham',\n",
        "    'MDL': 'Moldovan Leu',\n",
        "    'MGA': 'Malagasy Ariary',\n",
        "    'MKD': 'Macedonian Denar',\n",
        "    'MMK': 'Myanmar Kyat',\n",
        "    'MNT': 'Mongolian Tögrög',\n",
        "    'MOP': 'Macanese Pataca',\n",
        "    'MRU': 'Mauritanian Ouguiya',\n",
        "    'MUR': 'Mauritian Rupee',\n",
        "    'MVR': 'Maldivian Rufiyaa',\n",
        "    'MZN': 'Mozambican Metical',\n",
        "    'NAD': 'Namibian Dollar',\n",
        "    'NIO': 'Nicaraguan Córdoba',\n",
        "    'NOK': 'Norwegian Krone',\n",
        "    'NZD': 'New Zealand Dollar',\n",
        "    'PAB': 'Panamanian Balboa',\n",
        "    'PEN': 'Peruvian Sol',\n",
        "    'PGK': 'Papua New Guinean Kina',\n",
        "    'PYG': 'Paraguayan Guaraní',\n",
        "    'QAR': 'Qatari Riyal',\n",
        "    'RON': 'Romanian Leu',\n",
        "    'RSD': 'Serbian Dinar',\n",
        "    'RWF': 'Rwandan Franc',\n",
        "    'SBD': 'Solomon Islands Dollar',\n",
        "    'SDG': 'Sudanese Pound',\n",
        "    'SHP': 'Saint Helena Pound',\n",
        "    'SOS': 'Somali Shilling',\n",
        "    'SRD': 'Surinamese Dollar',\n",
        "    'SSP': 'South Sudanese Pound',\n",
        "    'STN': 'São Tomé and Príncipe Dobra',\n",
        "    'SVC': 'Salvadoran Colón',\n",
        "    'SYP': 'Syrian Pound',\n",
        "    'SZL': 'Eswatini Lilangeni',\n",
        "    'TJS': 'Tajikistani Somoni',\n",
        "    'TMT': 'Turkmenistani Manat',\n",
        "    'TND': 'Tunisian Dinar',\n",
        "    'TOP': 'Tongan Paʻanga',\n",
        "    'TTD': 'Trinidad and Tobago Dollar',\n",
        "    'TWD': 'New Taiwan Dollar',\n",
        "    'UAH': 'Ukrainian Hryvnia',\n",
        "    'UYU': 'Uruguayan Peso',\n",
        "    'UZS': 'Uzbekistani Som',\n",
        "    'VES': 'Venezuelan Bolívar',\n",
        "    'VUV': 'Vanuatu Vatu',\n",
        "    'WST': 'Samoan Tālā',\n",
        "    'XAF': 'Central African CFA Franc',\n",
        "    'XCD': 'East Caribbean Dollar',\n",
        "    'XPF': 'CFP Franc',\n",
        "    'ZMW': 'Zambian Kwacha',\n",
        "    'ZWG': 'Zimbabwean Gold'\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8pL-VBA2TE9"
      },
      "outputs": [],
      "source": [
        "!which python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uiEs2YDqrZo_"
      },
      "outputs": [],
      "source": [
        "len(currency_name_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOTVJqsLqVcf"
      },
      "outputs": [],
      "source": [
        "currency_symbol_dict = {\n",
        "    # --- SAFE: DISTINCT SYMBOLS ---\n",
        "    'EUR': '€',       # Euro\n",
        "    'GBP': '£',       # British Pound Sterling\n",
        "    'INR': '₹',       # Indian Rupee\n",
        "    'JPY': 'JP¥',     # Japanese Yen\n",
        "    'CNY': 'CN¥',     # Chinese Yuan\n",
        "    'RUB': '₽',       # Russian Ruble\n",
        "    'NGN': '₦',       # Nigerian Naira\n",
        "    'THB': '฿',       # Thai Baht\n",
        "    'VND': '₫',       # Vietnamese Dong\n",
        "    # 'KRW': '₩',       # South Korean Won\n",
        "    # 'KPW': '₩',       # North Korean Won\n",
        "    'TRY': '₺',       # Turkish Lira\n",
        "    'GHS': '₵',       # Ghanaian Cedi\n",
        "    'PHP': '₱',       # Philippine Peso\n",
        "    'ILS': '₪',       # Israeli New Shekel\n",
        "    'CRC': '₡',       # Costa Rican Colón\n",
        "    'PLN': 'zł',      # Polish Zloty\n",
        "    'CZK': 'Kč',      # Czech Koruna\n",
        "    'MNT': '₮',       # Mongolian Tögrög\n",
        "    'UAH': '₴',       # Ukrainian Hryvnia\n",
        "    'GEL': '₾',       # Georgian Lari\n",
        "    'AMD': '֏',       # Armenian Dram\n",
        "    'AZN': '₼',       # Azerbaijani Manat\n",
        "    'KZT': '₸',       # Kazakhstani Tenge\n",
        "    'LAK': '₭',       # Lao Kip\n",
        "    'KHR': '៛',       # Cambodian Riel\n",
        "    'BGN': 'лв',      # Bulgarian Lev\n",
        "    'MKD': 'ден',     # Macedonian Denar\n",
        "    'RSD': 'дин',     # Serbian Dinar\n",
        "\n",
        "    # --- ARABIC / DISTINCT SCRIPTS ---\n",
        "    'AED': 'د.إ',     # UAE Dirham\n",
        "    'SAR': 'ر.س',     # Saudi Riyal\n",
        "    'DZD': 'د.ج',     # Algerian Dinar\n",
        "    'LYD': 'ل.د',     # Libyan Dinar\n",
        "    'MAD': 'د.م.',    # Moroccan Dirham\n",
        "    'IQD': 'ع.د',     # Iraqi Dinar\n",
        "    # 'IRR': '﷼',       # Iranian Rial\n",
        "    # 'YER': '﷼',       # Yemeni Rial\n",
        "    'OMR': 'ر.ع.',    # Omani Rial\n",
        "    'QAR': 'ر.ق',     # Qatari Riyal\n",
        "    'JOD': 'د.ا',     # Jordanian Dinar\n",
        "    'KWD': 'د.ك',     # Kuwaiti Dinar\n",
        "    'TND': 'د.ت',     # Tunisian Dinar\n",
        "    'SDG': 'ج.س.',    # Sudanese Pound\n",
        "    'LBP': 'ل.ل',     # Lebanese Pound\n",
        "    'AFN': '؋',       # Afghan Afghani\n",
        "    'BHD': '.د.ب',    # Bahraini Dinar\n",
        "    'NPR': 'रू',      # Nepalese Rupee\n",
        "    'BDT': '৳',       # Bangladeshi Taka\n",
        "\n",
        "    # --- DOLLAR VARIANTS (KEPT AS REQUESTED) ---\n",
        "    'USD': 'US$',       # US Dollar\n",
        "    # 'ARS': '$',       # Argentine Peso\n",
        "    # 'CLP': '$',       # Chilean Peso\n",
        "    # 'COP': '$',       # Colombian Peso\n",
        "    'MXN': 'MEX$',     # Mexican Peso\n",
        "    'AUD': 'A$',      # Australian Dollar\n",
        "    'CAD': 'C$',      # Canadian Dollar\n",
        "    'SGD': 'S$',      # Singapore Dollar\n",
        "    'BRL': 'R$',      # Brazilian Real\n",
        "    'HKD': 'HK$',     # Hong Kong Dollar\n",
        "    'NZD': 'NZ$',     # New Zealand Dollar\n",
        "    # 'BSD': 'B$',      # Bahamian Dollar\n",
        "    'BZD': 'BZ$',     # Belize Dollar\n",
        "    'JMD': 'J$',      # Jamaican Dollar\n",
        "    'TTD': 'TT$',     # Trinidad and Tobago Dollar\n",
        "    'XCD': 'EC$',     # East Caribbean Dollar\n",
        "    'FJD': 'FJ$',     # Fijian Dollar\n",
        "    'SBD': 'SI$',     # Solomon Islands Dollar\n",
        "    'KYD': 'CI$',     # Cayman Islands Dollar\n",
        "    'LRD': 'L$',      # Liberian Dollar\n",
        "    'NAD': 'N$',      # Namibian Dollar\n",
        "    'UYU': '$U',      # Uruguayan Peso,\n",
        "     'SRD': 'Sr$',     # Surinamese Dollar (Suggesting 'Sr$' for distinctness),\n",
        "    'EGP':'E£',\n",
        "    # 'BND': 'B$',\n",
        "    'DOP':'RD$',\n",
        "    'GYD':'G$',\n",
        "    # 'KGS':'⃀',\n",
        "    'MOP': 'MOP$',    # Macanese Pataca\n",
        "    'PAB':'B/.',\n",
        "    'PEN': 'S/.',      # Peruvian Sol\n",
        "    'PYG': '₲',       # Paraguayan Guaraní,\n",
        "    'SOS':'Sh.So.',\n",
        "    'SYP': '£S',      # Syrian Pound\n",
        "    'TOP': 'T$',      # Tongan Paʻanga\n",
        "     'TWD': 'NT$',     # New Taiwan Dollar\n",
        "\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEyVma7arSoz"
      },
      "outputs": [],
      "source": [
        "len(currency_symbol_dict)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "currency_symbol_dict"
      ],
      "metadata": {
        "id": "hd92nT6lKPkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHfqjBRvciQx"
      },
      "outputs": [],
      "source": [
        "currency_acronym_dict = {code: code for code, name in currency_name_dict.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8i21-IdXHBbl"
      },
      "outputs": [],
      "source": [
        "currency_name_dict = {k: \" \" + v + \" \" for k, v in currency_name_dict.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glc1OrE9Wuu5"
      },
      "outputs": [],
      "source": [
        "currency_name_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2m9tNy8e8CG"
      },
      "outputs": [],
      "source": [
        "currency_terms_dict = {'currency_name_dict':currency_name_dict, 'currency_acronym_dict':currency_acronym_dict, 'currency_symbol_dict':currency_symbol_dict}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMZSw7aQTn-W"
      },
      "outputs": [],
      "source": [
        "currency_name_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmK1g6ugRACv"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLGWm_nlOcWA"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.max_colwidth', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwEE6qhA76Gd"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "ds_fin = load_dataset(\"FinanceMTEB/Final\")\n",
        "ds_fin = ds_fin['test'].to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMU_8gCW8uXw"
      },
      "outputs": [],
      "source": [
        "currency_symbol_dict.values()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGfceDuNCiWv"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "# regex pattern to match any of the currency symbols\n",
        "currency_symbols_for_pattern = [re.escape(symbol) for symbol in ['$']]\n",
        "\n",
        "currency_pattern = '|'.join(currency_symbols_for_pattern)\n",
        "\n",
        "# rows where either sentence1 or sentence2 contains any of the currency symbols\n",
        "all_currency_symbol_rows = ds_fin[\n",
        "    ds_fin['sentence1'].str.contains(currency_pattern, regex=True, na=False) |\n",
        "    ds_fin['sentence2'].str.contains(currency_pattern, regex=True, na=False)\n",
        "]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3ZCtKZ_C12m"
      },
      "outputs": [],
      "source": [
        "# from sentence_transformers import SentenceTransformer\n",
        "from datasets import load_dataset\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.stats import spearmanr\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fooe4v3fBWu3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdW8z3aSOmpD"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "# Create a regex pattern to match Euro (€) or British Pound (£) symbols and 'dollar'\n",
        "currency_symbols_for_pattern_new = [re.escape('€'), re.escape('£'), re.escape('dollar'), re.escape('euro'), re.escape('eur'), re.escape('gbp'), re.escape('Australian')]\n",
        "new_currency_pattern = '|'.join(currency_symbols_for_pattern_new)\n",
        "\n",
        "# Find rows where either sentence1 or sentence2 contains any of the specified currency symbols\n",
        "ignore_rows = all_currency_symbol_rows[\n",
        "    all_currency_symbol_rows['sentence1'].str.contains(new_currency_pattern, regex=True, na=False, flags=re.IGNORECASE) |\n",
        "    all_currency_symbol_rows['sentence2'].str.contains(new_currency_pattern, regex=True, na=False, flags=re.IGNORECASE)\n",
        "]\n",
        "print(\"Rows containing either '€', '£', or 'dollar' (case-insensitive) symbols:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2c3514c"
      },
      "outputs": [],
      "source": [
        "\n",
        "rows_to_delete_indices = ignore_rows.index\n",
        "all_currency_symbol_rows = all_currency_symbol_rows.drop(rows_to_delete_indices)\n",
        "\n",
        "print(f\"Successfully deleted {len(rows_to_delete_indices)} rows from all_currency_symbol_rows.\")\n",
        "print(\"First 5 rows of the updated all_currency_symbol_rows DataFrame:\")\n",
        "# display(all_currency_symbol_rows)\n",
        "print(f\"New length of all_currency_symbol_rows: {len(all_currency_symbol_rows)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXD2q4u0BRWg",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "all_currency_symbol_rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jl_vmOm8C3hV"
      },
      "outputs": [],
      "source": [
        "len(all_currency_symbol_rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAngPtQKHBbo"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-wLg2XWHBbp"
      },
      "outputs": [],
      "source": [
        "device='cuda:0'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMuoLOMz2TFE"
      },
      "outputs": [],
      "source": [
        "# model_names_to_test_finsts =[\"ProsusAI/finbert\", \"FinLang/finance-embeddings-investopedia\",\"intfloat/multilingual-e5-large\",\n",
        "\n",
        "model_names_to_test_finsts=[\"Alibaba-NLP/gte-large-en-v1.5\",\"Alibaba-NLP/gte-multilingual-base\",\\\n",
        "                              \"jinaai/jina-embeddings-v2-base-en\",\"BAAI/bge-m3\",\"Snowflake/snowflake-arctic-embed-m-v1.5\",\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\",\"sentence-transformers/all-mpnet-base-v2\",\\\n",
        "                              \"Qwen/Qwen3-Embedding-0.6B\",\"Qwen/Qwen3-Embedding-4B\",\"google/embeddinggemma-300M\", \"intfloat/multilingual-e5-large-instruct\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5spcRS72TFE"
      },
      "outputs": [],
      "source": [
        "model_names_to_test_finsts+=[\"google/embeddinggemma-300M\", \"intfloat/multilingual-e5-large-instruct\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GByav_JJHBbp",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "for x in sorted(model_names_to_test_finsts):\n",
        "    print('x', x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjHoqqAggGD5"
      },
      "outputs": [],
      "source": [
        "len(set(model_names_to_test_finsts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ps3wmcQRHBbp"
      },
      "outputs": [],
      "source": [
        "len(model_names_to_test_finsts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUJlLVI2ddWq"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer\n",
        "from transformers.pipelines import Pipeline\n",
        "from transformers.pipelines import PIPELINE_REGISTRY\n",
        "\n",
        "\n",
        "class FinBERTPipeline(Pipeline):\n",
        "    def _sanitize_parameters(self, **kwargs):\n",
        "        preprocess_kwargs = {}\n",
        "        if \"max_length\" in kwargs:\n",
        "            preprocess_kwargs[\"max_length\"] = kwargs[\"max_length\"]\n",
        "        return {}, preprocess_kwargs, {}\n",
        "\n",
        "    def preprocess(self, inputs, **kwargs):\n",
        "        tokenizer = self.tokenizer\n",
        "        return tokenizer(inputs, return_tensors=self.framework, padding=True, truncation=True, **kwargs)\n",
        "\n",
        "    def _forward(self, model_inputs, **kwargs):\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(**model_inputs, output_hidden_states=True)\n",
        "            # Typically, the last hidden state of the [CLS] token is used as the sentence embedding\n",
        "            cls_token_embeddings = outputs.hidden_states[-1][:, 0, :].cpu().numpy()\n",
        "        return {\"embeddings\": cls_token_embeddings}\n",
        "\n",
        "    def postprocess(self, model_outputs, **kwargs):\n",
        "        return model_outputs[\"embeddings\"]\n",
        "\n",
        "# Register the custom pipeline\n",
        "PIPELINE_REGISTRY.register_pipeline(\n",
        "    \"finbert-embedding\",\n",
        "    pipeline_class=FinBERTPipeline,\n",
        "    pt_model=AutoModelForSequenceClassification,\n",
        "    default={\"model\": \"ProsusAI/finbert\", \"revision\": \"main\"}\n",
        ")\n",
        "\n",
        "print(\"FinBERTPipeline class defined and registered.\")\n",
        "\n",
        "\n",
        "def embed_using_finbert(pipe, list_text):\n",
        "\n",
        "    all_embeddings_list = pipe(list_text, padding=True, truncation=True, max_length=128)\n",
        "\n",
        "    return all_embeddings_list\n",
        "\n",
        "\n",
        "\n",
        "finbert_model = AutoModelForSequenceClassification.from_pretrained('ProsusAI/finbert').to(device)\n",
        "finbert_tokenizer = AutoTokenizer.from_pretrained('ProsusAI/finbert')\n",
        "finbert_pipe = pipeline(\n",
        "    \"finbert-embedding\",\n",
        "    model=finbert_model,\n",
        "    tokenizer=finbert_tokenizer,\n",
        "    device=device )\n",
        "currency_embeddings_map = embed_using_finbert(finbert_pipe, ['a','b'])\n",
        "\n",
        "\n",
        "\n",
        "def encode_text(list_text, model_name, embedding_model):\n",
        "    if model_name == 'ProsusAI/finbert':\n",
        "        return np.array(embed_using_finbert(finbert_pipe, list_text))\n",
        "    else:\n",
        "        return embedding_model.encode(list_text, convert_to_numpy=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTS1dvfje4f7"
      },
      "outputs": [],
      "source": [
        "len(set(model_names_to_test_finsts)), len(model_names_to_test_finsts)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "directory_path = \"/output/STS_Exp/\""
      ],
      "metadata": {
        "id": "UR7hlhhE2pbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fa2315b",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.stats import spearmanr\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import re\n",
        "from IPython.display import display\n",
        "\n",
        "replacement_categories = ['symbol', 'acronym', 'name']\n",
        "\n",
        "print(\"Starting extended correlation analysis for different models and currency replacement strategies...\")\n",
        "for current_model_name in model_names_to_test_finsts:\n",
        "    all_correlation_results = []\n",
        "\n",
        "    try:\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"Loading model: {current_model_name}\")\n",
        "        print(f\"{'='*80}\\n\")\n",
        "\n",
        "\n",
        "        try:\n",
        "\n",
        "            if current_model_name=='ProsusAI/finbert':\n",
        "                model = None\n",
        "                print('model_name', current_model_name)\n",
        "            else:\n",
        "              model = SentenceTransformer(current_model_name, device=device, trust_remote_code=True)\n",
        "              print('model device ', model.device)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {current_model_name}: {e}. Skipping this model.\")\n",
        "            continue\n",
        "\n",
        "        for currency_code in list(currency_name_dict.keys()):\n",
        "            symbol_val = currency_symbol_dict.get(currency_code)\n",
        "            acronym_val = currency_acronym_dict.get(currency_code)\n",
        "            name_val = currency_name_dict.get(currency_code)\n",
        "\n",
        "            current_currency_replacements = {\n",
        "                'symbol': symbol_val,\n",
        "                'acronym': acronym_val,\n",
        "                'name': name_val\n",
        "            }\n",
        "\n",
        "            # Generate all 3x3 combinations of replacement categories\n",
        "            for strategy_s1 in replacement_categories:\n",
        "                for strategy_s2 in replacement_categories:\n",
        "                    s1_replace_term = current_currency_replacements.get(strategy_s1)\n",
        "                    s2_replace_term = current_currency_replacements.get(strategy_s2)\n",
        "                    if (strategy_s1 == 'symbol' and s1_replace_term is None) or \\\n",
        "                       (strategy_s2 == 'symbol' and s2_replace_term is None):\n",
        "                        print(f\"    Skipping {currency_code}: S1='{strategy_s1}' (missing symbol) or S2='{strategy_s2}' (missing symbol)\")\n",
        "                        continue\n",
        "                    df_modified = all_currency_symbol_rows.copy()#.head()\n",
        "\n",
        "                    # Perform replacements\n",
        "                    df_modified['sentence1'] = df_modified['sentence1'].str.replace(re.escape('$'), str(s1_replace_term), regex=True)\n",
        "                    df_modified['sentence2'] = df_modified['sentence2'].str.replace(re.escape('$'), str(s2_replace_term), regex=True)\n",
        "\n",
        "\n",
        "                    sentence1_embeddings = np.array(encode_text(df_modified['sentence1'].tolist()[:], current_model_name, model)).squeeze()\n",
        "                    sentence2_embeddings = np.array(encode_text(df_modified['sentence2'].tolist()[:], current_model_name, model)).squeeze()\n",
        "                    cosine_scores = np.diag(cosine_similarity(sentence1_embeddings, sentence2_embeddings))\n",
        "\n",
        "\n",
        "\n",
        "                    # Calculate Spearman correlation\n",
        "                    spearman_corr, pvalue = spearmanr(cosine_scores, df_modified['score'])\n",
        "\n",
        "                    del df_modified\n",
        "                    del sentence1_embeddings\n",
        "                    del sentence2_embeddings\n",
        "\n",
        "                    all_correlation_results.append({\n",
        "                        'Model Name': current_model_name,\n",
        "                        'Currency Code': currency_code,\n",
        "                        'Strategy S1': strategy_s1,\n",
        "                        'Replaced S1 With': s1_replace_term,\n",
        "                        'Strategy S2': strategy_s2,\n",
        "                        'Replaced S2 With': s2_replace_term,\n",
        "                        'Spearman Correlation': spearman_corr,\n",
        "                        'pvalue': pvalue\n",
        "                    })\n",
        "                    print(f\"    SC: {spearman_corr:.4f} , pv:{pvalue:.4f} \",)\n",
        "\n",
        "        df_correlation_summary_extended = pd.DataFrame(all_correlation_results)\n",
        "\n",
        "\n",
        "        with open(f'{directory_path}/STS_FINAL_{current_model_name.replace(\"/\",\"_\")}.pkl', 'wb') as f:\n",
        "            pickle.dump(df_correlation_summary_extended, f)\n",
        "\n",
        "        print('df_correlation_summary_extended', current_model_name)\n",
        "        display(df_correlation_summary_extended)\n",
        "\n",
        "        del model\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing model {current_model_name}: {e}\")\n",
        "        continue\n",
        "\n",
        "\n",
        "df_correlation_summary_extended = pd.DataFrame(all_correlation_results)\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"Final Summary of Extended Spearman Correlations:\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "display(df_correlation_summary_extended.sort_values(by='Spearman Correlation', ascending=False).reset_index(drop=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXFnqUabIOV4"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "directory_path =\"/output/STS_Exp/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d330e4aa"
      },
      "source": [
        "# Load and Consolidate Results\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "093ec7eb"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "all_dfs = []\n",
        "if not os.path.exists(directory_path):\n",
        "    print(f\"Directory not found: {directory_path}\")\n",
        "else:\n",
        "    for filename in os.listdir(directory_path):\n",
        "        if filename.startswith('STS_FINAL_') and filename.endswith('.pkl'):\n",
        "            file_path = os.path.join(directory_path, filename)\n",
        "            print(f\"Loading file: {file_path}\")\n",
        "            try:\n",
        "                df = pd.read_pickle(file_path)\n",
        "                all_dfs.append(df)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {filename}: {e}\")\n",
        "if all_dfs:\n",
        "    consolidated_df = pd.concat(all_dfs, ignore_index=True)\n",
        "    print(\"\\nConsolidated DataFrame head:\")\n",
        "    display(consolidated_df.head())\n",
        "    print(f\"\\nTotal rows in consolidated DataFrame: {len(consolidated_df)}\")\n",
        "else:\n",
        "    print(\"No matching pickle files found or loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vWeQVeop4tDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxGCNK-yOzLw"
      },
      "outputs": [],
      "source": [
        "consolidated_df.head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model wise average"
      ],
      "metadata": {
        "id": "z36RheWGUS1U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adc31a19"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "avg_spearman_corr_per_model = consolidated_df.groupby('Model Name')['Spearman Correlation'].mean().sort_values(ascending=False)\n",
        "\n",
        "print(\"Calculated average Spearman correlation per model.\")\n",
        "\n",
        "#Print the top 10 models\n",
        "print(\"\\nTop 10 Models by Average Spearman Correlation:\")\n",
        "print(avg_spearman_corr_per_model.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "512309e3"
      },
      "outputs": [],
      "source": [
        "avg_corr_by_strategy = consolidated_df.groupby(['Model Name', 'Strategy S1', 'Strategy S2'])['Spearman Correlation'].mean().unstack(level=[1, 2])\n",
        "print(\"Average Spearman Correlation grouped by model and replacement strategies (S1 and S2):\")\n",
        "display(avg_corr_by_strategy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6qs-VhhEy-z"
      },
      "outputs": [],
      "source": [
        "avg_corr_by_strategy.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1bc6dda"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(16, 10))\n",
        "sns.heatmap(avg_corr_by_strategy, annot=True, cmap='viridis', fmt=\".3f\", linewidths=.5)\n",
        "plt.title('Average Spearman Correlation by Model and Replacement Strategies', fontsize=16)\n",
        "plt.xlabel('Strategy S2', fontsize=12)\n",
        "plt.ylabel('Model Name / Strategy S1', fontsize=12)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Heatmap showing average Spearman correlation by model and replacement strategies has been generated.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plots"
      ],
      "metadata": {
        "id": "sgpMan5AUdDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "base_path = directory_path if 'directory_path' in locals() else \".\"\n",
        "plot_dir = os.path.join(base_path, 'plots')\n",
        "os.makedirs(plot_dir, exist_ok=True)\n",
        "\n",
        "# Bias metric Calculation\n",
        "bias_summary = consolidated_df.groupby('Model Name')['Spearman Correlation'].agg(['mean', 'std', 'min', 'max']).reset_index()\n",
        "bias_summary['Stability_Gap'] = bias_summary['max'] - bias_summary['min']\n",
        "bias_summary.to_csv(os.path.join(base_path, 'currency_bias_report.csv'), index=False)\n",
        "\n",
        "def plot_currency_bias(models, filename, title_suffix):\n",
        "    sns.set_theme(style=\"whitegrid\", palette=\"muted\")\n",
        "    plt.figure(figsize=(18, 11))\n",
        "\n",
        "    subset = consolidated_df[consolidated_df['Model Name'].isin(models)]\n",
        "    model_order = subset.groupby('Model Name')['Spearman Correlation'].median().sort_values(ascending=False).index\n",
        "\n",
        "    ax = sns.boxplot(\n",
        "        data=subset,\n",
        "        x='Model Name',\n",
        "        y='Spearman Correlation',\n",
        "        hue='Strategy Combo',\n",
        "        order=model_order,\n",
        "        palette='husl',\n",
        "        width=0.8,\n",
        "        linewidth=1.2,\n",
        "        fliersize=3\n",
        "    )\n",
        "\n",
        "    # TITLES & LARGE FONTS\n",
        "\n",
        "    plt.ylabel('Spearman Correlation', fontsize=24, labelpad=20)\n",
        "    plt.xlabel('', fontsize=20)\n",
        "\n",
        "    plt.xticks(rotation=35, ha='right', fontsize=26)\n",
        "    plt.yticks(fontsize=26)\n",
        "\n",
        "    plt.legend(\n",
        "        title='Strategy Pair (S1 / S2)',\n",
        "        bbox_to_anchor=(1.01, 1),\n",
        "        loc='upper left',\n",
        "        fontsize=16,\n",
        "        title_fontsize=18\n",
        "    )\n",
        "\n",
        "    plt.axhline(subset['Spearman Correlation'].mean(), color='red', linestyle='--', alpha=0.5)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    save_path = os.path.join(plot_dir, filename)\n",
        "    plt.savefig(save_path, format='pdf', bbox_inches='tight')\n",
        "    plt.show()\n",
        "all_models = sorted(consolidated_df['Model Name'].unique())\n",
        "mid = len(all_models) // 2\n",
        "\n",
        "plot_currency_bias(all_models[:mid], 'STS_bias_analysis_part1.pdf', '')\n",
        "plot_currency_bias(all_models[mid:], 'STS_bias_analysis_part2.pdf', '')\n",
        "\n",
        "print(f\"Bias analysis complete. PDF plots saved to: {plot_dir}\")"
      ],
      "metadata": {
        "id": "L7tF_ySG9JAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = directory_path if 'directory_path' in locals() else \".\"\n",
        "plot_dir = os.path.join(base_path, 'plots')"
      ],
      "metadata": {
        "id": "PDZKmYwoA0F8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_dir"
      ],
      "metadata": {
        "id": "HNKXTzrOA06C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "def plot_currency_bias_split(models_subset, filename, show_legend=True):\n",
        "    sns.set_theme(style=\"white\", palette=\"muted\")\n",
        "    sns.set_context(\"poster\", font_scale=0.8)\n",
        "    plt.figure(figsize=(20, 10))\n",
        "\n",
        "    subset = consolidated_df[consolidated_df['Model Name'].isin(models_subset)].copy()\n",
        "    subset['Short Model Name'] = subset['Model Name'].apply(lambda x: x.split('/')[-1])\n",
        "\n",
        "    model_order = subset.groupby('Short Model Name')['Spearman Correlation'].median().sort_values(ascending=False).index\n",
        "    palette = sns.color_palette(\"Paired\", 9)\n",
        "\n",
        "    ax = sns.boxplot(\n",
        "        data=subset,\n",
        "        x='Short Model Name',\n",
        "        y='Spearman Correlation',\n",
        "        hue='Strategy Combo',\n",
        "        order=model_order,\n",
        "        palette=palette,\n",
        "        width=0.8,\n",
        "        linewidth=2.0,\n",
        "        fliersize=4,\n",
        "        dodge=True\n",
        "    )\n",
        "\n",
        "    sns.despine(offset=10, trim=True)\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.3)\n",
        "    plt.ylabel('Spearman Correlation', fontsize=32, fontweight='bold', labelpad=25)\n",
        "    plt.xlabel('', fontsize=24)\n",
        "    plt.xticks(rotation=35, ha='right', fontsize=26, fontweight='medium')\n",
        "    plt.yticks(fontsize=26)\n",
        "    if show_legend:\n",
        "        plt.legend(\n",
        "            title='Strategy Pair (S1 / S2)',\n",
        "            bbox_to_anchor=(0.5, 1.01),\n",
        "            loc='lower center',\n",
        "            ncol=3,\n",
        "            fontsize=24,\n",
        "            title_fontsize=26,\n",
        "            frameon=True,\n",
        "            edgecolor='black',\n",
        "            framealpha=1\n",
        "        )\n",
        "        plt.tight_layout()\n",
        "        plt.subplots_adjust(top=0.78)\n",
        "        if ax.legend_:\n",
        "            ax.legend_.remove()\n",
        "        plt.tight_layout()\n",
        "\n",
        "\n",
        "    plt.axhline(consolidated_df['Spearman Correlation'].mean(), color='red', linestyle='--', linewidth=2, alpha=0.6)\n",
        "\n",
        "    save_path = os.path.join(plot_dir, filename)\n",
        "    plt.savefig(save_path, format='pdf', bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "plot_currency_bias_split(models_part1, 'STS_Part1_tight.pdf', show_legend=True)\n",
        "plot_currency_bias_split(models_part2, 'STS_Part2_tight.pdf', show_legend=False)"
      ],
      "metadata": {
        "id": "MN1l_--k9Jmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AyvfMGiVBXrI"
      },
      "outputs": [],
      "source": [
        "avg_corr_by_strategy.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ae2e8d8"
      },
      "outputs": [],
      "source": [
        "avg_corr_per_model_currency = consolidated_df.groupby(['Model Name', 'Currency Code'])['Spearman Correlation'].mean().unstack(level='Currency Code')\n",
        "\n",
        "print(\"Average Spearman Correlation per Model and Currency (rows are models, columns are currencies):\")\n",
        "display(avg_corr_per_model_currency)\n",
        "\n",
        "# display top models per currency\n",
        "print(\"\\nTop models per currency (showing the model with the highest average Spearman Correlation for each currency):\")\n",
        "for currency in avg_corr_per_model_currency.columns:\n",
        "    top_model = avg_corr_per_model_currency[currency].idxmax()\n",
        "    max_corr = avg_corr_per_model_currency[currency].max()\n",
        "    print(f\"  {currency}: {top_model} (Correlation: {max_corr:.4f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZq7SGbTRkTi"
      },
      "outputs": [],
      "source": [
        "consolidated_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8ed19b8"
      },
      "outputs": [],
      "source": [
        "unique_models = consolidated_df['Model Name'].unique()\n",
        "\n",
        "for model_name in unique_models:\n",
        "    print(f\"\\n{'='*100}\\nAnalyzing Model: {model_name}\\n{'='*100}\")\n",
        "    model_df = consolidated_df[consolidated_df['Model Name'] == model_name]\n",
        "    unique_strategies = model_df[['Strategy S1', 'Strategy S2']].drop_duplicates()\n",
        "\n",
        "    for _, row in unique_strategies.iterrows():\n",
        "        strategy_s1 = row['Strategy S1']\n",
        "        strategy_s2 = row['Strategy S2']\n",
        "\n",
        "        print(f\"\\n--- Strategy Combination: S1='{strategy_s1}', S2='{strategy_s2}' ---\")\n",
        "        filtered_strategy_df = model_df[\n",
        "            (model_df['Strategy S1'] == strategy_s1) &\n",
        "            (model_df['Strategy S2'] == strategy_s2)\n",
        "        ]\n",
        "\n",
        "        if not filtered_strategy_df.empty:\n",
        "            avg_corr_per_currency_strategy = filtered_strategy_df.groupby('Currency Code')['Spearman Correlation'].mean()\n",
        "\n",
        "            #top 5 currencies\n",
        "            top_5_currencies = avg_corr_per_currency_strategy.nlargest(5)\n",
        "            print(\"Top 5 Currencies:\")\n",
        "            print(top_5_currencies)\n",
        "\n",
        "            # bottom 5 currencies\n",
        "            bottom_5_currencies = avg_corr_per_currency_strategy.nsmallest(5)\n",
        "            print(\"Bottom 5 Currencies:\")\n",
        "            print(bottom_5_currencies)\n",
        "        else:\n",
        "            print(\"No data found for this strategy combination.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38eeb441"
      },
      "source": [
        "# Identify overall worst-performing currencies per model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52282bbd"
      },
      "source": [
        "# Calculate the average Spearman correlation for each model and currency, aggregating across all strategies\n",
        "avg_corr_per_model_currency_overall = consolidated_df.groupby(['Model Name', 'Currency Code'])['Spearman Correlation'].mean().unstack(level='Currency Code')\n",
        "\n",
        "print(\"\\nOverall Worst-performing Currencies per Model (averaged across all strategies):\")\n",
        "for model_name in avg_corr_per_model_currency_overall.index:\n",
        "    worst_5_currencies = avg_corr_per_model_currency_overall.loc[model_name].nsmallest(5)\n",
        "    print(f\"\\n--- Model: {model_name} ---\")\n",
        "    print(\"Worst 5 Currencies:\")\n",
        "    print(worst_5_currencies.round(4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbf260c6"
      },
      "source": [
        "## Analyze the best and worst performing currency pairs for each strategy combination for the 'intfloat/multilingual-e5-large-instruct' model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8806a55b"
      },
      "source": [
        "\n",
        "model_name_to_analyze = 'intfloat/multilingual-e5-large-instruct'\n",
        "model_df_filtered = consolidated_df[consolidated_df['Model Name'] == model_name_to_analyze]\n",
        "\n",
        "print(f\"Analyzing performance for model: {model_name_to_analyze}\")\n",
        "unique_strategy_combinations = model_df_filtered[['Strategy S1', 'Strategy S2']].drop_duplicates().values.tolist()\n",
        "\n",
        "for s1_strategy, s2_strategy in unique_strategy_combinations:\n",
        "    print(f\"\\n--- Strategy Combination: S1='{s1_strategy}', S2='{s2_strategy}' ---\")\n",
        "    current_strategy_df = model_df_filtered[\n",
        "        (model_df_filtered['Strategy S1'] == s1_strategy) &\n",
        "        (model_df_filtered['Strategy S2'] == s2_strategy)\n",
        "    ]\n",
        "\n",
        "    if not current_strategy_df.empty:\n",
        "        best_performance = current_strategy_df.loc[current_strategy_df['Spearman Correlation'].idxmax()]\n",
        "        print(\"  Best Performing Currency Pair:\")\n",
        "        print(f\"    Currency Code: {best_performance['Currency Code']}\")\n",
        "        print(f\"    Spearman Correlation: {best_performance['Spearman Correlation']:.4f}\")\n",
        "        print(f\"    Replaced S1 With: {best_performance['Replaced S1 With']}\")\n",
        "        print(f\"    Replaced S2 With: {best_performance['Replaced S2 With']}\")\n",
        "        worst_performance = current_strategy_df.loc[current_strategy_df['Spearman Correlation'].idxmin()]\n",
        "        print(\"  Worst Performing Currency Pair:\")\n",
        "        print(f\"    Currency Code: {worst_performance['Currency Code']}\")\n",
        "        print(f\"    Spearman Correlation: {worst_performance['Spearman Correlation']:.4f}\")\n",
        "        print(f\"    Replaced S1 With: {worst_performance['Replaced S1 With']}\")\n",
        "        print(f\"    Replaced S2 With: {worst_performance['Replaced S2 With']}\")\n",
        "    else:\n",
        "        print(\"  No data found for this strategy combination.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}